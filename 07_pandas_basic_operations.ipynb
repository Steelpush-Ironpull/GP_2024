{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    body {\n",
    "        --vscode-font-family: \"CMU Sans Serif\"\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output, HTML\n",
    "import time\n",
    "\n",
    "def countdown_timer(minutes):\n",
    "    total_seconds = minutes * 60\n",
    "    for seconds in range(total_seconds, 0, -1):\n",
    "        mins, secs = divmod(seconds, 60)\n",
    "        time_str = f\"{mins:02}'{secs:02}''\"\n",
    "        clear_output(wait=True)\n",
    "        # HTML with styling\n",
    "        display(HTML(f'<div style=\"font-size: 24px; color: blue; font-weight: bold;\">Time remaining: {time_str}</div>'))\n",
    "        time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    # Final message with different styling\n",
    "    display(HTML('<div style=\"font-size: 24px; color: green; font-weight: bold;\">Time\\'s up!</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg\" style=\"width: 500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://preview.redd.it/anyone-knows-where-this-comes-from-v0-qntrcv0walxc1.png?auto=webp&s=e6ea1f53405b160be57d251c243f2aac9f97d6ee\" style=\"width: 500px;\">\n",
    "    <figcaption style=\"font-size: 0.8em;\"> <code>pandas</code> has nothing to do with pandas: instead, the name is derived from the term \"panel data\",  as well as a play on the phrase \"Python data analysis\".<br> <code>pandas</code> hat nichts mit Pandas zu tun: Der Name leitet sich von dem Begriff \"panel data\" ab und ist eine Anspielung auf den Ausdruck \"Python-Datenanalyse\".</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "In the previous lecture, we explored how to plot and fit data using NumPy. In that approach, we generated NumPy arrays on the fly to create the axes for our plots. \n",
    "\n",
    "However, in many real-world scenarios, data comes from external files rather than being generated programmatically. \n",
    "\n",
    "While NumPy provides methods to read files, transforming data into **`pandas` DataFrames** offers significantly more power and convenience. \n",
    "\n",
    "For this reason, today we will focus on working with `pandas`, a versatile tool for handling and analyzing external datasets.\n",
    "\n",
    "`pandas` is a Python library that provides easy-to-use data structures and data analysis tools, making it ideal for handling and analyzing large datasets efficiently.\n",
    "\n",
    "`pandas` loads data into DataFrames (`df`), which you can think of as Excel sheets.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "In der vorangegangenen Vorlesung haben wir untersucht, wie man Daten mit NumPy darstellt und anpasst. Bei diesem Ansatz haben wir NumPy-Arrays on the fly generiert, um die Achsen für unsere Diagramme zu erstellen.\n",
    "\n",
    "In vielen realen Szenarien kommen die Daten jedoch aus externen Dateien und werden nicht programmatisch generiert.\n",
    "\n",
    "NumPy bietet zwar Methoden zum Lesen von Dateien, aber die Umwandlung von Daten in **`pandas` DataFrames** bietet wesentlich mehr Leistung und Komfort.\n",
    "\n",
    "Aus diesem Grund werden wir uns heute auf die Arbeit mit `pandas` konzentrieren, einem vielseitigen Werkzeug für den Umgang mit und die Analyse von externen Datensätzen.\n",
    "\n",
    "`pandas` ist eine Python-Bibliothek, die einfach zu verwendende Datenstrukturen und Datenanalysewerkzeuge bereitstellt und sich damit ideal für die effiziente Handhabung und Analyse großer Datensätze eignet.\n",
    "\n",
    "`pandas` lädt Daten in Datenrahmen (`df`), die man sich wie Excel-Tabellen vorstellen kann.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/01_table_dataframe.svg\" style=\"width: 400px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9c/Pandas_dataframe.png\" style=\"width: 700px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "There are many differences between `pandas` and Excel, but the most practical ones are the following:\n",
    "\n",
    "- Excel is a visual tool, which makes it easy to click a button that abstracts the function behind what you want to accomplish. To achieve the same function in `pandas`, you need to write a command. This setup is ideal for automating tasks instead of pointing and clicking all the time!\n",
    "\n",
    "- Any operation you perform in Excel changes your spreadsheet and, indeed, your data. Data in `pandas` is <i>persistent</i>, meaning you can perform operations on copies of your data while preserving the raw dataset.\n",
    "\n",
    "- You might not have noticed so far, but Excel is not designed to handle large datasets and complex operations. At some point in your career, Excel will crash when trying to load your data.\n",
    "        \n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Es gibt viele Unterschiede zwischen `pandas` und Excel, aber die praktischsten sind die folgenden:\n",
    "\n",
    "- Excel ist ein visuelles Werkzeug, das es einfach macht, auf eine Schaltfläche zu klicken, die die Funktion hinter dem, was man erreichen will, abstrahiert. Um die gleiche Funktion in `pandas` zu erreichen, müssen Sie einen Befehl schreiben. Dieser Aufbau ist ideal, um Aufgaben zu automatisieren, anstatt ständig auf eine Schaltfläche zu zeigen und zu klicken!\n",
    "\n",
    "- Jede Operation, die Sie in Excel durchführen, verändert Ihr Tabellenblatt und damit auch Ihre Daten. Daten in `pandas` sind <i>beständig</i>, d.h. Sie können Operationen an Kopien Ihrer Daten durchführen, während der Rohdatensatz erhalten bleibt.\n",
    "\n",
    "- Sie haben es vielleicht noch nicht bemerkt, aber Excel ist nicht dafür ausgelegt, große Datensätze und komplexe Operationen zu verarbeiten. Irgendwann in Ihrer Karriere wird Excel beim Versuch, Ihre Daten zu laden, abstürzen.\n",
    "        \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "In summary, Excel may appear easy, but it is very tedious and, most importantly, not reliable. \n",
    "\n",
    "`pandas` may seem complicated at first, but it greatly simplifies and enhances data handling and analysis.\n",
    "\n",
    "To use `pandas`, we import it. The community agreed alias for `pandas` is `pd`:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Zusammenfassend lässt sich sagen, dass Excel zwar einfach erscheint, aber sehr mühsam und vor allem nicht zuverlässig ist. \n",
    "\n",
    "`pandas` mag auf den ersten Blick kompliziert erscheinen, aber es vereinfacht und verbessert die Datenverarbeitung und -analyse erheblich.\n",
    "\n",
    "Um `pandas` zu verwenden, importieren wir es. Der von der Gemeinschaft vereinbarte Alias für `pandas` ist `pd`:\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "The key `pandas` data structures are *Series* and *DataFrame*, representing a one-dimensional sequence of values and a data table, respectively.\n",
    "\n",
    "A DataFrame has two axes:\n",
    "\n",
    "- Axis 0 (rows): This refers to the vertical direction, i.e., across the rows. Operations along axis 0 work on individual rows.\n",
    "\n",
    "- Axis 1 (columns): This refers to the horizontal direction, i.e., across the columns. Operations along axis 1 work on individual columns.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Die wichtigsten `pandas`-Datenstrukturen sind *Series* und *DataFrame*, die eine eindimensionale Folge von Werten bzw. eine Datentabelle darstellen.\n",
    "\n",
    "Ein DataFrame hat zwei Achsen:\n",
    "\n",
    "- Achse 0 (Zeilen): Dies bezieht sich auf die vertikale Richtung, d. h. über die Zeilen. Operationen entlang der Achse 0 wirken auf einzelne Zeilen.\n",
    "\n",
    "- Achse 1 (Spalten): Dies bezieht sich auf die horizontale Richtung, d. h. über die Spalten. Operationen entlang der Achse 1 wirken sich auf einzelne Spalten aus.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Reading data \n",
    "\n",
    "There are various methods to create a DataFrame or Series in Python, but in practice, we typically won’t be manually generating data from scratch. Instead, we’ll often be working with pre-existing datasets.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "## Daten lesen \n",
    "\n",
    "Es gibt verschiedene Methoden, um einen DataFrame oder eine Serie in Python zu erstellen, aber in der Praxis werden wir in der Regel nicht manuell Daten von Grund auf neu erzeugen. Stattdessen werden wir oft mit bereits vorhandenen Datensätzen arbeiten.\n",
    "\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "Data can come in a wide variety of formats, each suited to different use cases. \n",
    "\n",
    "All of these formats can be easily loaded into `pandas` using the appropriate `pd.read_` command.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Daten können in einer Vielzahl von Formaten vorliegen, die jeweils für unterschiedliche Anwendungsfälle geeignet sind.\n",
    "\n",
    "Alle diese Formate können mit dem entsprechenden `pd.read_`-Befehl leicht in `pandas` geladen werden.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/02_io_readwrite.svg\" style=\"width: 700px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Command               | File Type               | \n",
    "|-----------------------|-------------------------|\n",
    "| `pd.read_csv()`        | CSV                     | \n",
    "| `pd.read_excel()`      | Excel (XLS, XLSX)       | \n",
    "| `pd.read_json()`       | JSON                    | \n",
    "| `pd.read_html()`       | HTML                    | \n",
    "| `pd.read_sql()`        | SQL                     | \n",
    "| `pd.read_sql_query()`  | SQL Query               | \n",
    "| `pd.read_sql_table()`  | SQL Table               | \n",
    "| `pd.read_pickle()`     | Pickle                  | \n",
    "| `pd.read_feather()`    | Feather                 | \n",
    "| `pd.read_parquet()`    | Parquet                 | \n",
    "| `pd.read_orc()`        | ORC                     | \n",
    "| `pd.read_sas()`        | SAS                     | \n",
    "| `pd.read_spss()`       | SPSS                    | \n",
    "| `pd.read_stata()`      | Stata                   | \n",
    "| `pd.read_table()`      | General Delimited Text  | \n",
    "| `pd.read_fwf()`        | Fixed-Width Text        | \n",
    "| `pd.read_clipboard()`  | Clipboard               | \n",
    "| `pd.read_hdf()`        | HDF5                    | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Reading an Excel file (if we must)\n",
    "\n",
    "I know what you're thinking: \"Every dataset I've ever seen or created was made in Excel.\" \n",
    "\n",
    "Opening an Excel file is straightforward, and in this section, we'll show you even how to make small adjustments to clean up unwanted comments that don’t belong in a spreadsheet.<sup>*</sup>\n",
    "\n",
    "The Excel file `bond-lengths.xlsx` contains data on the bond lengths, vibrational constants and dissociation energies of some diatomic molecules. \n",
    "\n",
    "The single sheet is named \"Diatomics\". \n",
    "Column A contains the molecular formula; the first row (row `0`!) is a title, and the second row contains the column names. \n",
    "\n",
    "There is also a footer of two lines.\n",
    "\n",
    "<sup>*</sup> <span style=\"font-size: 0.8em;\">There is a prevalent tendency to use worksheets like notebook pages, where tabular data is often intermixed with comments, footnotes, and plots. While this may appear convenient at first, it results in disorganized data that can be difficult to clean up. For this reason, plain CSV files are a superior option. As mentioned in the first lecture, if you require a digital notebook, you should consider using Jupyter *notebooks*.</span>\n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Lesen einer Excel-Datei (wenn es sein muss)\n",
    "\n",
    "Ich weiß, was Sie jetzt denken: \"Jeder Datensatz, den ich je gesehen oder erstellt habe, wurde in Excel erstellt.\"\n",
    "\n",
    "Das Öffnen einer Excel-Datei ist ganz einfach, und in diesem Abschnitt zeigen wir Ihnen sogar, wie Sie kleine Anpassungen vornehmen können, um unerwünschte Kommentare zu entfernen, die nicht in ein Arbeitsblatt gehören.\n",
    "\n",
    "Die Excel-Datei `bond-lengths.xlsx` enthält Daten zu den Bindungslängen, Schwingungskonstanten und Dissoziationsenergien einiger zweiatomiger Moleküle.\n",
    "\n",
    "Das einzelne Blatt trägt den Namen \"Diatomeen\".\n",
    "Spalte A enthält die Molekülformel; die erste Zeile (Zeile `0`!) ist ein Titel, und die zweite Zeile enthält die Spaltennamen.\n",
    "\n",
    "Außerdem gibt es eine Fußzeile mit zwei Zeilen.\n",
    "\n",
    "<sup>*</sup> <span style=\"font-size: 0.8em;\">Es gibt eine weit verbreitete Tendenz, Arbeitsblätter wie Notizbuchseiten zu verwenden, in denen tabellarische Daten oft mit Kommentaren, Fußnoten und Diagrammen vermischt sind. Dies mag auf den ersten Blick bequem erscheinen, führt aber zu unübersichtlichen Daten, die schwer zu bereinigen sind. Aus diesem Grund sind einfache CSV-Dateien die bessere Wahl. Wie in der ersten Vorlesung erwähnt, sollten Sie, wenn Sie ein digitales Notizbuch benötigen, die Verwendung von Jupyter *Notebooks* in Betracht ziehen.</span>\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://scipython.com/static/media/2/examples/E9/xlsx-screenshot.png\" style=\"width: 700px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_lenghts = pd.read_excel('datasets/bond-lengths.xlsx',      # the file we want to open\n",
    "                             skipfooter=2,                      # ignore the last two lines of the sheet\n",
    "                             header=1,                          # take the column names from the second row\n",
    "                             )\n",
    "bond_lenghts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "A more refined set of commands:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Ein verfeinerter Satz von Befehlen:\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_lenghts = pd.read_excel('datasets/bond-lengths.xlsx',      # the file we want to open\n",
    "                             index_col=0,                       # use molecule names as index labels\n",
    "                             skipfooter=2,                      # ignore the last two lines of the sheet\n",
    "                             header=1,                          # take the column names from the second row\n",
    "                             usecols='A:E',                     # use Excel columns labeled A-E (optional)\n",
    "                             sheet_name='Diatomics'             # take data from this sheet (in case there are several)\n",
    "                             )\n",
    "\n",
    "bond_lenghts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Reading a CSV file\n",
    "\n",
    "One of the simplest and most common formats is the CSV (Comma-Separated Values) file. \n",
    "\n",
    "A CSV file is essentially a plain text file where each line represents a row of data, and the values in each row are separated by commas. \n",
    "\n",
    "When opened, a CSV file presents data in a straightforward, table-like format that looks something like this:\n",
    "\n",
    "```\n",
    "Name, Age, City\n",
    "Alice, 30, New York\n",
    "Bob, 25, London\n",
    "Charlie, 35, Paris\n",
    "```\n",
    "\n",
    "This basic structure makes CSV files widely used for storing and sharing tabular data across platforms, especially when working with spreadsheet applications or databases. \n",
    "\n",
    "Although CSV files are simple, they can still hold complex datasets, making them a powerful starting point for analysis with libraries like `pandas` in Python.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Lesen einer CSV-Datei\n",
    "\n",
    "Eines der einfachsten und gängigsten Formate ist die CSV-Datei (Comma-Separated Values).\n",
    "\n",
    "Eine CSV-Datei ist im Wesentlichen eine reine Textdatei, bei der jede Zeile eine Datenzeile darstellt und die Werte in jeder Zeile durch Kommas getrennt sind.\n",
    "\n",
    "Beim Öffnen einer CSV-Datei werden die Daten in einem einfachen, tabellenartigen Format dargestellt, das etwa so aussieht:\n",
    "\n",
    "```\n",
    "Name, Alter, Stadt\n",
    "Alice, 30, New York\n",
    "Bob, 25, London\n",
    "Charlie, 35, Paris\n",
    "```\n",
    "\n",
    "Aufgrund dieser Grundstruktur werden CSV-Dateien häufig für die Speicherung und den Austausch von Tabellendaten auf verschiedenen Plattformen verwendet, insbesondere bei der Arbeit mit Tabellenkalkulationsprogrammen oder Datenbanken.\n",
    "\n",
    "Obwohl CSV-Dateien einfach sind, können sie dennoch komplexe Datensätze enthalten, was sie zu einem leistungsstarken Ausgangspunkt für Analysen mit Bibliotheken wie `pandas` in Python macht.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "We'll use the `pd.read_csv()` function to read the data into a DataFrame.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Wir verwenden die Funktion `pd.read_csv()`, um die Daten in einen DataFrame zu lesen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv('datasets/wine_reviews_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "###  First inspection \n",
    "\n",
    "Let's look at it:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "### Erste Inspektion \n",
    "\n",
    "Schauen wir es uns an:\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "When calling the DataFrame, `pandas` displays a brief summary, showing the first 5 and last 5 rows along with an overview. \n",
    "\n",
    "This includes the total number of rows and columns, in this case, 15093 rows and 11 columns.\n",
    "\n",
    "In addition to the summary provided when calling the DataFrame, `pandas` offers specific methods for quickly inspecting data:\n",
    "\n",
    "1. `head()` returns the first few rows of the DataFrame, with 5 rows being the default. It's useful for getting a quick look at the beginning of the dataset. You can pass an argument to specify a different number of rows, for example, `df.head(10)` would display the first 10 rows.\n",
    "\n",
    "   ```python\n",
    "   df.head()  # Displays the first 5 rows\n",
    "   ```\n",
    "\n",
    "2. `tail()` returns the last few rows of the DataFrame, with the default being 5 rows. This helps you check the data at the end of the dataset. You can also specify how many rows to display by passing a number, like `df.tail(10)` for the last 10 rows.\n",
    "\n",
    "   ```python\n",
    "   df.tail()  # Displays the last 5 rows\n",
    "   ```\n",
    "\n",
    "3. `shape` provides the dimensions of the DataFrame in the form of a tuple: `(number_of_rows, number_of_columns)`. It's useful when you want to know the size of your dataset at a glance. For example, `df.shape` would return `(15093, 11)` for a DataFrame with 150,930 rows and 11 columns.\n",
    "\n",
    "   ```python\n",
    "   df.shape  # Outputs (150930, 11)\n",
    "   ```\n",
    "\n",
    "4. A check on how `pandas` interpreted each of the column data types can be done by requesting the `dtypes` attribute:\n",
    "\n",
    "   ```python\n",
    "   df.dtypes \n",
    "   ```\n",
    "\n",
    "5. `df.columns` gives you access to the column names of a DataFrame, allowing you to view or change them as needed.\n",
    "\n",
    "   ```python\n",
    "   df.columns                                               # Returns the column names\n",
    "   df.columns = ['new_name1', 'new_name2', 'new_name3']     # Renames columns\n",
    "   ```\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.4;color: grey;\">\n",
    "\n",
    "Beim Aufruf des DataFrame zeigt `pandas` eine kurze Zusammenfassung mit den ersten 5 und den letzten 5 Zeilen sowie eine Übersicht an.\n",
    "\n",
    "Dazu gehört auch die Gesamtzahl der Zeilen und Spalten, in diesem Fall 15093 Zeilen und 11 Spalten.\n",
    "\n",
    "Zusätzlich bietet `pandas` spezielle Methoden für die schnelle Inspektion von Daten:\n",
    "\n",
    "1. `head()` gibt die ersten paar Zeilen des DataFrame zurück, wobei 5 Zeilen der Standard sind. Es ist nützlich, um einen schnellen Blick auf den Anfang des Datensatzes zu werfen. Sie können ein Argument übergeben, um eine andere Anzahl von Zeilen anzugeben, z. B. würde `df.head(10)` die ersten 10 Zeilen anzeigen.\n",
    "\n",
    "   ```python\n",
    "   df.head() # Zeigt die ersten 5 Zeilen an\n",
    "   ```\n",
    "\n",
    "2. `tail()` gibt die letzten Zeilen des DataFrame zurück, wobei die Vorgabe 5 Zeilen sind. Dies hilft Ihnen, die Daten am Ende des Datensatzes zu überprüfen. Sie können auch angeben, wie viele Zeilen angezeigt werden sollen, indem Sie eine Zahl übergeben, z. B. `df.tail(10)` für die letzten 10 Zeilen.\n",
    "\n",
    "   ```python\n",
    "   df.tail() # Zeigt die letzten 5 Zeilen an\n",
    "   ```\n",
    "\n",
    "3. `shape` liefert die Dimensionen des DataFrame in Form eines Tupels: `(Anzahl_der_Zeilen, Anzahl_der_Spalten)`. Es ist nützlich, wenn Sie die Größe Ihres Datensatzes auf einen Blick erkennen wollen. Zum Beispiel würde `df.shape` `(15093, 11)` für einen DataFrame mit 150.930 Zeilen und 11 Spalten zurückgeben.\n",
    "\n",
    "   ```python\n",
    "   df.shape # Outputs (150930, 11)\n",
    "   ```\n",
    "\n",
    "4. Eine Überprüfung, wie `pandas` die einzelnen Datentypen der Spalten interpretiert hat, kann durch Abfrage des Attributs `dtypes` erfolgen:\n",
    "\n",
    "   ```python\n",
    "   df.dtypes\n",
    "   ```\n",
    "\n",
    "5. Mit \"df.columns\" können Sie auf die Spaltennamen eines DataFrame zugreifen und sie bei Bedarf anzeigen oder ändern:\n",
    "\n",
    "   ```python\n",
    "   df.columns # Liefert die Spaltennamen\n",
    "   df.columns = ['neuer_name1', 'neuer_name2', 'neuer_name3'] # Benennt Spalten um\n",
    "   ```\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Use the commands we've just covered to display the column names, the first 15 rows, the last 15 rows, the dimensions, and the data types of the `wine_reviews` dataset.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "Verwenden Sie die soeben behandelten Befehle, um die Spaltennamen, die ersten 15 Zeilen, die letzten 15 Zeilen, die Abmessungen und die Datentypen des Datensatzes `wine_reviews` anzuzeigen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countdown\n",
    "countdown_timer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Data types\n",
    "\n",
    "Data types provide insight into how the data is stored internally. For example, `float64` represents a 64-bit floating point number, while `int64` refers to a 64-bit integer.\n",
    "\n",
    "An important thing to note, as seen clearly here, is that columns containing only strings are not assigned a specific string type. Instead, they are classified as `object` type.\n",
    "\n",
    "You can easily convert a column from one data type to another, as long as the conversion is valid, using the `astype()` function.\n",
    "\n",
    "For instance, you can convert the `points` column from its current `int64` data type to `float64` like this:\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Datentypen\n",
    "\n",
    "Datentypen geben Aufschluss darüber, wie die Daten intern gespeichert werden. `float64` steht zum Beispiel für eine 64-Bit-Gleitkommazahl, während `int64` sich auf eine 64-Bit-Ganzzahl bezieht.\n",
    "\n",
    "Wichtig ist, wie hier deutlich zu sehen, dass Spalten, die nur Zeichenketten enthalten, kein bestimmter Zeichenkettentyp zugewiesen wird. Stattdessen werden sie als object`-Typ klassifiziert.\n",
    "\n",
    "Sie können eine Spalte leicht von einem Datentyp in einen anderen umwandeln, solange die Umwandlung gültig ist, indem Sie die Funktion `astype()` verwenden.\n",
    "\n",
    "So können Sie beispielsweise die Spalte `points` von ihrem derzeitigen Datentyp `int64` in `float64` umwandeln:\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews['points'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Missing values\n",
    "\n",
    "Entries with missing values are represented by `NaN`, which stands for \"Not a Number.\" Due to technical reasons, these `NaN` values are always of the `float64` data type, regardless of the original data type of the column.\n",
    "\n",
    "`NaN` values aren't inherently problematic, but certain operations (like divisions) or statistical analyses can produce errors or yield skewed results when missing values are involved.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Datentypen\n",
    "\n",
    "Einträge mit fehlenden Werten werden durch `NaN` dargestellt, was für \"Not a Number\" steht. Aus technischen Gründen haben diese `NaN`-Werte immer den Datentyp `float64`, unabhängig vom ursprünglichen Datentyp der Spalte.\n",
    "\n",
    "`NaN`-Werte sind an sich nicht problematisch, aber bestimmte Operationen (z. B. Divisionen) oder statistische Analysen können zu Fehlern führen oder verzerrte Ergebnisse liefern, wenn fehlende Werte beteiligt sind.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "`pandas` provides several built-in methods to handle missing values in DataFrames and Series. \n",
    "\n",
    "- The `isnull()` and `notnull()` methods are used to detect missing values in a DataFrame or Series. They return a boolean mask indicating where `NaN` values are present (`True` for `NaN`, `False` otherwise).\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "`pandas` bietet mehrere integrierte Methoden zur Behandlung fehlender Werte in DataFrames und Reihen.\n",
    "\n",
    "- Die Methoden `isnull()` und `notnull()` werden verwendet, um fehlende Werte in einem DataFrame oder einer Serie zu erkennen. Sie geben eine boolesche Maske zurück, die angibt, wo `NaN`-Werte vorhanden sind (`True` für `NaN`, sonst `False`).\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df.isnull()                     # Returns a DataFrame of booleans indicating NaN locations\n",
    "\n",
    "df[df['column_name'].isnull()]  # Returns rows where 'column_name' is NaN\n",
    "\n",
    "df.notnull()                    # Returns a DataFrame of booleans indicating non-NaN locations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "- The `dropna()` method is used to remove rows or columns that contain `NaN` values. This is useful if you want to exclude missing data from your analysis entirely.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "- Die Methode `dropna()` wird verwendet, um Zeilen oder Spalten zu entfernen, die `NaN`-Werte enthalten. Dies ist nützlich, wenn Sie fehlende Daten vollständig aus Ihrer Analyse ausschließen möchten.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df.dropna()                               # Removes rows with at least one NaN\n",
    "\n",
    "df.dropna(axis=1)                         # Removes columns with at least one NaN\n",
    "\n",
    "df.dropna(subset=['column1', 'column2'])  # Removes rows with NaN in the specified columns\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "- The `fillna()` method is used to replace `NaN` values with a specified value or by following certain strategies (such as forward filling or backward filling).\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "- Die Methode `fillna()` wird verwendet, um `NaN`-Werte durch einen bestimmten Wert oder durch bestimmte Strategien (wie \"forward filling\" oder \"backward filling\") zu ersetzen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df['column_name'].fillna(0)                          # Replaces NaN with `0` in a specific column\n",
    "\n",
    "df['column_name'].fillna('Unknown')                  # Replaces NaN with the string Unknown in a specific column\n",
    "\n",
    "df['column_name'].fillna(df['column_name'].mean())   # Fill with the mean, median, or mode (of the column)\n",
    "df['column_name'].fillna(df['column_name'].median())\n",
    "df['column_name'].fillna(df['column_name'].mode())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. The `isnull()` function returns a DataFrame of boolean values (`True` for missing values and `False` for non-missing values). To count how many `NaN` values there are in each column, you can sum the boolean values because `True` is treated as `1` and `False` as `0` in `pandas`. By summing the result of `isnull()` for each column, you'll get the total count of missing values. Count how many missing values there are in each column using `isnull()`. \n",
    "\n",
    "2. Remove all rows where the `region_2` column has missing values.\n",
    "\n",
    "3. Replace all missing values in the `price` column with the median price.\n",
    "\n",
    "4. Fill missing values in the `points` column with the mean value of the column.\n",
    "\n",
    "5. What are the most common wine-producing regions? Count the occurrences of each value in the `region_1` column. Since this field often has missing data, replace any `NaN` values with 'Unknown' before counting.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "1. Die Funktion \"isnull()\" gibt einen DataFrame mit booleschen Werten zurück (`True` für fehlende Werte und `False` für nicht fehlende Werte). Um zu zählen, wie viele `NaN`-Werte es in jeder Spalte gibt, kann man die booleschen Werte summieren, da `True` als `1` und `False` als `0` in `pandas` behandelt wird. Wenn Sie das Ergebnis von `isnull()` für jede Spalte addieren, erhalten Sie die Gesamtzahl der fehlenden Werte. Zählen Sie mit `isnull()`, wie viele fehlende Werte es in jeder Spalte gibt.\n",
    "\n",
    "2. Entfernen Sie alle Zeilen, in denen die Spalte `region_1` fehlende Werte enthält.\n",
    "\n",
    "3. Ersetze alle fehlenden Werte in der Spalte `Preis` durch den Medianpreis.\n",
    "\n",
    "4. Fülle fehlende Werte in der Spalte `points` mit dem Mittelwert der Spalte auf.\n",
    "\n",
    "5. Welches sind die häufigsten Weinbauregionen? Zählen Sie die Häufigkeit der einzelnen Werte in der Spalte \"Region_1\". Da in diesem Feld häufig Daten fehlen, ersetzen Sie vor der Zählung alle \"NaN\"-Werte durch \"Unbekannt\".\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv('datasets/wine_reviews_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "1. **Task**: Count how many missing values there are in each column using `isnull()`.\n",
    "\n",
    "   ```python\n",
    "   wine_reviews.isnull().sum()\n",
    "   ```\n",
    "\n",
    "2. **Task**: Remove all rows where the `region_2` column has missing values.\n",
    "\n",
    "   ```python\n",
    "   wine_reviews.dropna(subset=['region_2'], inplace=True)\n",
    "   ```\n",
    "\n",
    "3. **Task**: Replace all missing values in the `price` column with the median price.\n",
    "\n",
    "   ```python\n",
    "   median_price = wine_reviews['price'].median()\n",
    "   wine_reviews['price'].fillna(median_price)\n",
    "   ```\n",
    "\n",
    "4. **Task**: Fill missing values in the `points` column with the mean value of the column.\n",
    "\n",
    "   ```python\n",
    "   mean_points = wine_reviews['points'].mean()\n",
    "   wine_reviews['points'].fillna(mean_points)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Indexing (yes, again) \n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "## Indizierung (ja, schon wieder) \n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "### Selecting specific columns\n",
    "\n",
    "Just as we can access dictionary values using their keys, we can access the columns of a DataFrame using the `[]` indexing operator.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "### Auswahl von bestimmten Spalten\n",
    "\n",
    "Genauso wie wir auf Wörterbuchwerte über ihre Schlüssel zugreifen können, können wir auf die Spalten eines DataFrame mit dem Indizierungsoperator `[]` zugreifen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/03_subset_columns.svg\" style=\"height: 150px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "To select multiple columns, use a list of column names within the selection brackets `[]`.\n",
    "\n",
    "The inner square brackets define a Python list with column names, whereas the outer brackets are used to select the data from a pandas DataFrame as seen in the previous example.\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "Um mehrere Spalten auszuwählen, verwenden Sie eine Liste von Spaltennamen innerhalb der Auswahlklammern `[]`.\n",
    "\n",
    "Die inneren eckigen Klammern definieren eine Python-Liste mit Spaltennamen, während die äußeren Klammern verwendet werden, um die Daten aus einem Pandas DataFrame auszuwählen, wie im vorherigen Beispiel zu sehen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews[['country','province']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Select the `description` column from the `wine_reviews` dataset and assign the result to a variable called `desc`.\n",
    "\n",
    "What type of object is `desc`? If you're not sure, you can check by calling Python's `type` function: `type(desc)`.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "Wählen Sie die Spalte `description` aus dem Datensatz `wine_reviews` aus und weisen Sie das Ergebnis einer Variablen namens `desc` zu.\n",
    "\n",
    "Welcher Typ von Objekt ist `desc`? Wenn Sie sich nicht sicher sind, können Sie das mit der Python-Funktion `type` überprüfen: `type(desc)`.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "### Filtering specific rows\n",
    "\n",
    "To select rows based on a conditional expression, use a condition inside the selection brackets `[]`.\n",
    "\n",
    "Only rows for which the condition is True will be displayed.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "### Auswahl von bestimmten Spalten\n",
    "\n",
    "Um Zeilen auf der Grundlage eines bedingten Ausdrucks auszuwählen, verwenden Sie eine Bedingung innerhalb der Auswahlklammern `[]`.\n",
    "\n",
    "Es werden nur Zeilen angezeigt, für die die Bedingung wahr ist.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/03_subset_rows.svg\" style=\"height: 150px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the rows where country is Italy\n",
    "\n",
    "wine_reviews[wine_reviews['country'] == 'Italy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "When combining multiple conditional statements, each condition must be surrounded by parentheses `()`. Moreover, you can not use `or`/`and` but need to use the `or` operator `|` and the `and` operator `&`.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "Bei der Kombination mehrerer bedingter Anweisungen muss jede Bedingung von Klammern `()` umgeben sein. Außerdem können Sie nicht `oder`/`und` verwenden, sondern müssen den `oder`-Operator `|` und den `und`-Operator `&` verwenden.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the rows where country is Italy\n",
    "\n",
    "wine_reviews[(wine_reviews['country'] == 'Italy') | (wine_reviews['country'] == 'France')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Alternative: `df.query()`\n",
    "\n",
    "There is a more compact way to attain the same result.\n",
    "\n",
    "`df.query()` allows you to refer to column names directly *without using brackets and quotes* and with `and` and `or` operators. \n",
    "\n",
    "It’s cleaner when filtering based on multiple conditions or column names with spaces.\n",
    "\n",
    "However, it is less versatile and less flexible than the previous syntax.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Alternative: `df.query()`\n",
    "\n",
    "Es gibt einen kompakteren Weg, um das gleiche Ergebnis zu erzielen.\n",
    "\n",
    "Mit `df.query()` können Sie direkt auf Spaltennamen verweisen *ohne Klammern und Anführungszeichen* und mit den Operatoren `und` und `oder`.\n",
    "\n",
    "Das ist sauberer, wenn man auf der Grundlage mehrerer Bedingungen oder Spaltennamen mit Leerzeichen filtert.\n",
    "\n",
    "Allerdings ist sie weniger vielseitig und weniger flexibel als die vorherige Syntax.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.query('country == \"Italy\" or country == \"France\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "In terms of data structures, a DataFrame column is a Series, which is similar to a list. \n",
    "\n",
    "Therefore, it’s no surprise that we can use the indexing operator `[]` again to isolate specific elements within that column.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "In Bezug auf die Datenstrukturen ist eine DataFrame-Spalte eine Reihe, die einer Liste ähnlich ist.\n",
    "\n",
    "Daher ist es keine Überraschung, dass wir den Indexierungsoperator `[]` wieder verwenden können, um bestimmte Elemente innerhalb dieser Spalte zu isolieren.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews['country'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "### Selecting specific rows *and* columns\n",
    "\n",
    "In this case, a subset of both rows and columns is made in one go and just using selection brackets `[]` is not sufficient anymore. \n",
    "\n",
    "The `loc`/`iloc` operators are required in front of the selection brackets `[]`. \n",
    "\n",
    "When using `loc`/`iloc`, the part before the comma is the rows you want, and the part after the comma is the columns you want to select.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "### Auswahl bestimmter Zeilen *und* Spalten\n",
    "\n",
    "In diesem Fall wird eine Teilmenge von sowohl Zeilen als auch Spalten in einem Durchgang ausgewählt, und die Verwendung von Auswahlklammern `[]` ist nicht mehr ausreichend.\n",
    "\n",
    "Die Operatoren `loc`/`iloc` werden vor den Auswahlklammern `[]` benötigt.\n",
    "\n",
    "Bei der Verwendung von `loc`/`iloc` steht der Teil vor dem Komma für die gewünschten Zeilen und der Teil nach dem Komma für die Spalten, die Sie auswählen möchten.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/03_subset_columns_rows.svg\" style=\"height: 150px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "These are specialized `pandas` operators designed for more advanced indexing operations:\n",
    "\n",
    "- `iloc`: Allows you to access data by integer positions (row/column indices).\n",
    "\n",
    "- `loc`: Allows you to access data by labels (row/column names).\n",
    "\n",
    "For more complex data manipulation tasks, such as filtering by conditions, selecting specific rows or columns, or slicing data based on both row and column labels, `loc` and `iloc` are the preferred methods to use. They offer greater flexibility and control over how you work with DataFrames.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3; color: grey;\">\n",
    "\n",
    "Dies sind spezialisierte `pandas`-Operatoren, die für fortgeschrittene Indizierungsoperationen entwickelt wurden:\n",
    "\n",
    "- `iloc`: Ermöglicht den Zugriff auf Daten über ganzzahlige Positionen (Zeilen/Spalten-Indizes).\n",
    "- `loc`: Ermöglicht den Zugriff auf Daten über Bezeichnungen (Zeilen/Spaltennamen).\n",
    "\n",
    "Für komplexere Datenmanipulationsaufgaben, wie z. B. das Filtern nach Bedingungen, die Auswahl bestimmter Zeilen oder Spalten oder das Aufteilen von Daten auf Grundlage von Zeilen- und Spaltenbeschriftungen, sind `loc` und `iloc` die bevorzugten Methoden. Sie bieten mehr Flexibilität und Kontrolle bei der Arbeit mit DataFrames.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "### Label-based selection: `loc` \n",
    "\n",
    "The `loc` function in `pandas` is used for **label-based indexing**, which allows you to select rows and columns from a DataFrame using their labels or index names. \n",
    "\n",
    "`loc` works with the actual names of rows and columns, making it more intuitive when dealing with labeled data.\n",
    "\n",
    "**Row and Column Selection by Label**: You can use `loc` to access data by row and column labels. The second index (if present) identifies the column(s).\n",
    "\n",
    "The first index identifies one or more rows by the index name or list of names.\n",
    "\n",
    "For example, `df.loc['row_label']` selects the row with the specified label, and `df.loc[:, 'column_label']` selects the column by name.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "### Etikettenbasierte Auswahl: `loc` \n",
    "\n",
    "`loc` wird für die **Label-basierte Indizierung** verwendet, die es erlaubt, Zeilen und Spalten aus einem DataFrame anhand ihrer Labels oder Indexnamen auszuwählen.\n",
    "\n",
    "`loc` arbeitet mit den tatsächlichen Namen von Zeilen und Spalten, was es intuitiver macht, wenn man mit beschrifteten Daten arbeitet.\n",
    "\n",
    "**Zeilen- und Spaltenauswahl nach Bezeichnung**: Sie können \"loc\" verwenden, um auf Daten über Zeilen- und Spaltenbezeichnungen zuzugreifen. Der zweite Index (falls vorhanden) identifiziert die Spalte(n).\n",
    "\n",
    "Der erste Index identifiziert eine oder mehrere Zeilen durch den Indexnamen oder eine Liste von Namen.\n",
    "\n",
    "Zum Beispiel wählt `df.loc['row_label']` die Zeile mit der angegebenen Bezeichnung aus, und `df.loc[:, 'column_label']` wählt die Spalte nach dem Namen aus.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access the first row of the dataset:\n",
    "\n",
    "wine_reviews.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an equivalent to access the first row of the dataset:\n",
    "\n",
    "wine_reviews.loc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Multiple Rows:\n",
    "\n",
    "wine_reviews.loc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a Single Column:\n",
    "\n",
    "wine_reviews.loc[:, 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Multiple Columns:\n",
    "\n",
    "wine_reviews.loc[:, ['country', 'points']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "**Single Element Selection**: You can retrieve a single value by specifying both the row and column labels. For instance, `df.loc['row_label', 'column_label']` retrieves the specific element from that row and column.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "**Einzelne Elementauswahl**: Sie können einen einzelnen Wert abrufen, indem Sie sowohl die Zeilen- als auch die Spaltenbezeichnung angeben. Zum Beispiel ruft `df.loc['row_label', 'column_label']` das spezifische Element aus dieser Zeile und Spalte ab.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a Specific Element:\n",
    "\n",
    "wine_reviews.loc[0, 'points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "**Boolean Indexing**: One of the most powerful features of `loc` is the ability to filter rows based on conditions. You can pass a boolean array or condition to `loc` to select rows that meet a specific criterion. For example, `df.loc[df['Age'] > 30]`  selects rows where the `Age` column is greater than 30.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "**Boolesche Indizierung**: Eine der mächtigsten Funktionen von `loc` ist die Möglichkeit, Zeilen anhand von Bedingungen zu filtern. Sie können ein boolesches Array oder eine Bedingung an `loc` übergeben, um Zeilen auszuwählen, die ein bestimmtes Kriterium erfüllen. Zum Beispiel wählt `df.loc[df['Alter'] > 30]` die Zeilen aus, in denen die Spalte `Alter` größer als 30 ist.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Rows by Condition:\n",
    "\n",
    "wine_reviews.loc[wine_reviews['points'] >= 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "Boolean indexing with *multiple conditions* allows you to filter a DataFrame based on multiple criteria. \n",
    "\n",
    "You combine conditions using logical operators like `&` (`and`), `|` (`or`), and `~` (`not`).\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Die boolesche Indizierung mit *Mehrfachbedingungen* ermöglicht es Ihnen, einen DataFrame nach mehreren Kriterien zu filtern.\n",
    "\n",
    "Sie kombinieren Bedingungen mit logischen Operatoren wie `&` (`and`), `|` (`or`), und `~` (`not`).\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Rows by Multiple Conditions:\n",
    "# Pay attention to parentheses\n",
    "\n",
    "wine_reviews.loc[(wine_reviews['points'] >= 90) & (wine_reviews['price'] >= 300)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. Filter all wines from Italy.\n",
    "\n",
    "2. Select all wines from Napa Valley with a score of 95 or higher.\n",
    "\n",
    "3. Get all columns for the first 10 rows of French wines.\n",
    "\n",
    "4. Select specific columns (`country`, `points`, `price`) for wines with 90+ points.\n",
    "\n",
    "5. Get all wines with a price of over $100 and display only `variety` and `winery`.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "1. Filtern Sie alle Weine aus Italien.\n",
    "\n",
    "2. Wählen Sie alle Weine aus Napa Valley mit einer Bewertung von 95 oder höher.\n",
    "\n",
    "3. Ermitteln Sie alle Spalten für die ersten 10 Zeilen der französischen Weine.\n",
    "\n",
    "4. Wählen Sie bestimmte Spalten (`country`, `points`, `price`) für Weine mit 90+ Punkten.\n",
    "\n",
    "5. Erhalten Sie alle Weine mit einem Preis von über $100 und zeigen Sie nur `variety` und `winery` an.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "1. **Filter all wines from Italy**:\n",
    "   - Use `loc` to select all rows where the `country` column is labeled as \"Italy\".\n",
    "   ```python\n",
    "   italian_wines = df.loc[df['country'] == 'Italy']\n",
    "   ```\n",
    "\n",
    "2. **Select all wines from Napa Valley with a score of 95 or higher**:\n",
    "   - Filter wines by region (`region_1`) and their `points` column.\n",
    "   ```python\n",
    "   napa_top_wines = df.loc[(df['region_1'] == 'Napa Valley') & (df['points'] >= 95)]\n",
    "   ```\n",
    "\n",
    "3. **Get all columns for the first 10 rows of French wines**:\n",
    "   - Use `loc` to select all columns from the first 10 rows where the `country` is \"France\".\n",
    "   ```python\n",
    "   french_wines = df.loc[df['country'] == 'France'].head(10)\n",
    "   ```\n",
    "\n",
    "4. **Select specific columns (`country`, `points`, `price`) for wines with 90+ points**:\n",
    "   - Use `loc` to filter wines with high points and show specific columns.\n",
    "   ```python\n",
    "   high_point_wines = df.loc[df['points'] >= 90, ['country', 'points', 'price']]\n",
    "   ```\n",
    "\n",
    "5. **Get all wines with a price of over $100 and display only `variety` and `winery`**:\n",
    "   - Use `loc` to filter by price and select specific columns.\n",
    "   ```python\n",
    "   expensive_wines = df.loc[df['price'] > 100, ['variety', 'winery']]\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Alternative: `df.query()` (again)\n",
    "\n",
    "Again, we can attain the same result with the help of `df.query()`:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "#### Alternative: `df.query()` (erneut)\n",
    "\n",
    "Auch hier können wir das gleiche Ergebnis mit Hilfe von `df.query()` erreichen:\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.query('points >= 90 and price >= 300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. Find all wines from California priced under $50:\n",
    "   - Use `query` to filter by `province` and `price`.\n",
    "\n",
    "2. Select wines from France with a score above 90 and price between $20 and $100:\n",
    "   - Use `query` to filter by multiple conditions.\n",
    "\n",
    "3. Find all wines with a variety of \"Pinot Noir\" and a score of 95 or higher:\n",
    "   - Use `query` to filter by `variety` and `points`.\n",
    "\n",
    "4. Get wines from Oregon with a score between 90 and 95:\n",
    "   - Use `query` to filter by region and points range.\n",
    "\n",
    "5. Filter wines from Napa Valley that cost more than $200:\n",
    "   - Use `query` to find high-end wines from a specific region.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "1. Finden Sie alle Weine aus Kalifornien mit einem Preis unter $50:\n",
    "   - Verwenden Sie `query`, um nach `province` und `price` zu filtern.\n",
    "\n",
    "2. Wählen Sie Weine aus Frankreich mit einer Punktzahl über 90 und einem Preis zwischen $20 und $100:\n",
    "   - Verwenden Sie `query`, um nach mehreren Bedingungen zu filtern.\n",
    "\n",
    "3. Finden Sie alle Weine mit der Sorte \"Pinot Noir\" und einer Punktzahl von 95 oder höher:\n",
    "   - Verwenden Sie `query`, um nach `variety` und `points` zu filtern.\n",
    "\n",
    "4. Finden Sie Weine aus Oregon mit einer Punktzahl zwischen 90 und 95:\n",
    "   - Verwenden Sie `query`, um nach Region und Punktzahl zu filtern.\n",
    "\n",
    "5. Filtern Sie Weine aus dem Napa Valley, die mehr als 200 $ kosten:\n",
    "   - Verwenden Sie `query`, um Spitzenweine aus einer bestimmten Region zu finden.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "1. **Find all wines from California priced under $50**:\n",
    "   - Use `query` to filter by `province` and `price`.\n",
    "   ```python\n",
    "   affordable_california_wines = df.query('province == \"California\" and price < 50')\n",
    "   ```\n",
    "\n",
    "2. **Select wines from France with a score above 90 and price between $20 and $100**:\n",
    "   - Use `query` to filter by multiple conditions.\n",
    "   ```python\n",
    "   french_high_score_wines = df.query('country == \"France\" and points > 90 and 20 <= price <= 100')\n",
    "   ```\n",
    "\n",
    "3. **Find all wines with a variety of \"Pinot Noir\" and a score of 95 or higher**:\n",
    "   - Use `query` to filter by `variety` and `points`.\n",
    "   ```python\n",
    "   top_pinot_noir = df.query('variety == \"Pinot Noir\" and points >= 95')\n",
    "   ```\n",
    "\n",
    "4. **Get wines from Oregon with a score between 90 and 95**:\n",
    "   - Use `query` to filter by region and points range.\n",
    "   ```python\n",
    "   oregon_wines = df.query('province == \"Oregon\" and points >= 90 and points <= 95')\n",
    "   ```\n",
    "\n",
    "5. **Filter wines from Napa Valley that cost more than $200**:\n",
    "   - Use `query` to find high-end wines from a specific region.\n",
    "   ```python\n",
    "   luxury_napa_wines = df.query('region_1 == \"Napa Valley\" and price > 200')\n",
    "   ```\n",
    "\n",
    "These tasks will help you explore the wine reviews dataset and use different `pandas` functions (`loc`, `iloc`, and `query`) for data selection and filtering based on various criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "###  Index-based selection: `iloc`\n",
    "\n",
    "The `iloc` function in `pandas` is used for **positional indexing**. \n",
    "\n",
    "It allows you to select rows and columns from a DataFrame based on their integer positions rather than their labels.\n",
    "\n",
    "- **Row and column selection**: You can use `iloc` to select rows and columns by their numeric position. For example, `iloc[0]` selects the first row, and `iloc[:, 1]` selects the second column. This indexing system is zero-based, meaning the first element is at position 0.\n",
    "\n",
    "- **Single Element Selection:**: You can select a single element by specifying both row and column indices, like `df.iloc[2, 3]`, which retrieves the value from the third row and fourth column.\n",
    "\n",
    "- **Slicing**: `iloc` supports slicing, just like Python lists. You can select a range of rows or columns using a slice notation: `iloc[1:4]` selects rows 1, 2, and 3). Both the start and stop indices are integers, and the slicing follows Python's convention: it includes the start index but excludes the stop index.\n",
    "\n",
    "- **Selecting Entire Rows or Columns**: To select all rows or all columns, use a colon (:) as a placeholder. For instance, `df.iloc[:, 0]` retrieves all rows from the first column, while `df.iloc[0, :]` retrieves all columns from the first row.\n",
    "\n",
    "- **Negative Indexing**: Like Python lists, `iloc` supports negative indexing, which allows you to count from the end of the DataFrame. For example, `df.iloc[-1]` selects the last row.\n",
    "\n",
    "- **Mixing Indexing Types**: You can mix scalar values (specific indices) with slices in the same call. For example, `df.iloc[0, 1:3]` selects the first row and the second and third columns.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "### Indexbasierte Auswahl: `iloc`\n",
    "\n",
    "Die Funktion `iloc` in `pandas` wird für die **positionsbezogene Indizierung** verwendet.\n",
    "\n",
    "Sie ermöglicht es, Zeilen und Spalten aus einem DataFrame anhand ihrer ganzzahligen Positionen und nicht anhand ihrer Beschriftungen auszuwählen.\n",
    "\n",
    "- **Zeilen- und Spaltenauswahl**: Sie können `iloc` verwenden, um Zeilen und Spalten nach ihrer numerischen Position auszuwählen. Zum Beispiel wählt `iloc[0]` die erste Zeile und `iloc[:, 1]` die zweite Spalte aus. Dieses Indexierungssystem ist nullbasiert, d.h. das erste Element befindet sich an Position 0.\n",
    "\n",
    "- **Einzelne Elementauswahl:**: Sie können ein einzelnes Element auswählen, indem Sie sowohl Zeilen- als auch Spaltenindizes angeben, z. B. `df.iloc[2, 3]`, das den Wert aus der dritten Zeile und der vierten Spalte abruft.\n",
    "\n",
    "- **Slicing**: `iloc` unterstützt Slicing, genau wie Python-Listen. Sie können einen Bereich von Zeilen oder Spalten auswählen, indem Sie eine Slice-Notation verwenden (z. B. wählt `iloc[1:4]` die Zeilen 1, 2 und 3 aus). Sowohl der Start- als auch der Stop-Index sind Ganzzahlen, und das Slicing folgt der Python-Konvention: Es schließt den Start-Index ein, aber den Stop-Index aus.\n",
    "\n",
    "- **Gesamte Zeilen oder Spalten auswählen**: Um alle Zeilen oder alle Spalten auszuwählen, verwenden Sie einen Doppelpunkt (:) als Platzhalter. Zum Beispiel ruft `df.iloc[:, 0]` alle Zeilen ab der ersten Spalte ab, während `df.iloc[0, :]` alle Spalten ab der ersten Zeile abruft.\n",
    "\n",
    "- **Negative Indizierung**: Wie Python-Listen unterstützt `iloc` negative Indizierung, die es erlaubt, vom Ende des DataFrame aus zu zählen. Zum Beispiel wählt `df.iloc[-1]` die letzte Zeile aus.\n",
    "\n",
    "- **Mischung von Indizierungsarten**: Sie können skalare Werte (spezifische Indizes) mit Slices im selben Aufruf mischen. Zum Beispiel wählt `df.iloc[0, 1:3]` die erste Zeile sowie die zweite und dritte Spalte aus.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. Select the first 20 rows of the dataset.\n",
    "\n",
    "2. Extract rows 50 to 100 and display columns 0, 2, and 3.\n",
    "\n",
    "3. Get the last 10 rows of the dataset.\n",
    "\n",
    "4. Select every third row and first three columns from the first 50 rows.\n",
    "\n",
    "5. Retrieve rows 5 to 15 and only the first two columns.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "1. Wählen Sie die ersten 20 Zeilen des Datensatzes aus.\n",
    "\n",
    "2. Extrahieren Sie die Zeilen 50 bis 100 und zeigen Sie die Spalten 0, 2 und 3 an.\n",
    "\n",
    "3. Holen Sie die letzten 10 Zeilen des Datensatzes.\n",
    "\n",
    "4. Wählen Sie jede dritte Zeile und die ersten drei Spalten der ersten 50 Zeilen aus.\n",
    "\n",
    "5. Rufen Sie die Zeilen 5 bis 15 und nur die ersten beiden Spalten ab.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "1. **Select the first 20 rows of the dataset**:\n",
    "   - Use `iloc` to extract the first 20 rows.\n",
    "   ```python\n",
    "   first_20_rows = df.iloc[:20]\n",
    "   ```\n",
    "\n",
    "2. **Extract rows 50 to 100 and display columns 0, 2, and 3**:\n",
    "   - Use `iloc` to select a range of rows and specific columns by position.\n",
    "   ```python\n",
    "   partial_data = df.iloc[50:101, [0, 2, 3]]\n",
    "   ```\n",
    "\n",
    "3. **Get the last 10 rows of the dataset**:\n",
    "   - Use `iloc` to retrieve the last 10 rows.\n",
    "   ```python\n",
    "   last_10_rows = df.iloc[-10:]\n",
    "   ```\n",
    "\n",
    "4. **Select every third row and first three columns from the first 50 rows**:\n",
    "   - Use `iloc` to get a subset of rows and columns with a step.\n",
    "   ```python\n",
    "   subset = df.iloc[0:50:3, :3]\n",
    "   ```\n",
    "\n",
    "5. **Retrieve rows 5 to 15 and only the first two columns**:\n",
    "   - Use `iloc` to access a specific range of rows and columns.\n",
    "   ```python\n",
    "   specific_rows_cols = df.iloc[5:16, :2]\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                        | `iloc`                                                                 | `loc`                                                                                     | `query`                                                          |\n",
    "|------------------------------|------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
    "| **Type of Indexing**          | Positional (integer-based)                                              | Label-based (row/column labels)                                                           | SQL-like filtering based on column names                         |\n",
    "| **Selection Method**          | Selects by integer positions                                            | Selects by labels (row/column names)                                                      | Filters rows based on column conditions                          |\n",
    "| **Row Access**                | `df.iloc[0]`)                                   |  `df.loc['row_label']`)                                                |  `df.query('column > value')`)           |\n",
    "| **Column Access**             | `df.iloc[:, 1]`)                                |  `df.loc[:, 'column_label']`)                                          | No, only filters rows                                            |\n",
    "| **Slicing**                   | `df.iloc[0:3, 1:4]`)                                         | `df.loc['row1':'row3', 'col1':'col3']`)                                         | No                                                |\n",
    "| **Boolean Filtering**         | No                                                                     | `df.loc[df['column'] > value]`)                                                 |  `df.query('column > value')`)                         |\n",
    "| **Condition-based Filtering** | No                                                                     |  `df.loc[(df['col'] > value) & (df['col2'] == value2)]`) |  `df.query('col > value and col2 == value2')`) |\n",
    "| **Handling of Index Labels**  | No (works only with integer positions)                                  |  `df.loc['row_label']`)                                 | No (works only with column names, not index)                     |\n",
    "| **Ease of Use**               | Best for integer-based selection                                        | Best for label-based access and flexibility                                                | Best for filtering rows with simple conditions                   |\n",
    "| **Multi-index Support**       | No                                                                     | Yes                                                         | No                                                               |\n",
    "| **Reference to Variables**    | No                                                                     | Yes, using Python variables directly: `df.loc[df['column'] > var]`)                  | Yes, using `@` symbol for variables: `df.query('col > @var')`) |\n",
    "| **Selection of Rows/Columns** |  `df.iloc[1, 2]`)               |  `df.loc['row', 'column']`)                          | Only rows, no direct column selection                            |\n",
    "| **Querying on Conditions**    | No                                                                     |  `df.loc[df['col'] > 30, ['col1', 'col2']]`)                   |  `df.query('col > 30')`)             |\n",
    "| **Advanced Use Cases**        | Best for slicing and positional indexing                                | Best for label-based indexing, multi-index, and complex filtering                          | Best for readable condition-based filtering with complex conditions |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "Most `pandas` operations return *copies* of the DataFrame. \n",
    "To make the changes “stick”, you’ll need to assign the result of any slicing or filtering operation to a new DataFrame, allowing you to create subsets of the original data:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Die meisten `pandas`-Operationen geben *Kopien* des DataFrame zurück.\n",
    "Damit die Änderungen \"haften\" bleiben, müssen Sie das Ergebnis jeder Slicing- oder Filter-Operation einem neuen DataFrame zuweisen, so dass Sie Teilmengen der ursprünglichen Daten erstellen können:\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_wines = wine_reviews.query('country == \"Italy\"')\n",
    "\n",
    "italian_wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Assigning values\n",
    "\n",
    "You can override entire columns:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "## Zuweisung von Werten\n",
    "\n",
    "Sie können ganze Spalten außer Kraft setzen:\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is 50% off!\n",
    "\n",
    "wine_reviews[\"price\"] = wine_reviews[\"price\"] / 2\n",
    "\n",
    "wine_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Creating new columns\n",
    "\n",
    "`pandas` supports mathematical operations directly on DataFrame columns, allowing you to easily create new columns based on existing ones. \n",
    "\n",
    "You can perform operations like addition, subtraction, multiplication, division, etc., between columns. \n",
    "\n",
    "The operation is applied element-wise (row by row): you do not need to use a loop to iterate each of the rows!\n",
    "\n",
    "To create a new column, use the `[]` brackets with the new column name at the left side of the assignment.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "## Erstellen neuer Spalten\n",
    "\n",
    "`pandas` unterstützt mathematische Operationen direkt auf DataFrame-Spalten, so dass Sie auf einfache Weise neue Spalten auf der Grundlage bestehender Spalten erstellen können.\n",
    "\n",
    "Sie können Operationen wie Addition, Subtraktion, Multiplikation, Division usw. zwischen den Spalten durchführen.\n",
    "\n",
    "Die Operation wird elementweise (Zeile für Zeile) durchgeführt: Sie müssen keine Schleife verwenden, um jede Zeile zu durchlaufen!\n",
    "\n",
    "Um eine neue Spalte zu erstellen, verwenden Sie die Klammern `[]` mit dem Namen der neuen Spalte auf der linken Seite der Zuordnung.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/05_newcolumn_2.svg\" style=\"height: 150px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Examples\n",
    "df['C'] = df['A'] + 10\n",
    "df['D'] = df['A'] + df['B']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. As of September 2024, the USD/EUR conversion rate is 0.93. Create a new column that calculates and returns the price in EUR.\n",
    "\n",
    "2. Which wines offer the best value? Create a new column that calculates the ratio of points to price.\n",
    "\n",
    "Assign meaningful names to both of the new columns.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "1. Im September 2024 beträgt der Umrechnungskurs USD/EUR 0.93. Erstellen Sie eine neue Spalte, die den Preis in EUR berechnet und ausgibt.\n",
    "\n",
    "2. Welche Weine bieten das beste Preis-Leistungs-Verhältnis? Erstellen Sie eine neue Spalte, die das Verhältnis von Punkten zu Preis berechnet.\n",
    "\n",
    "Weisen Sie den beiden neuen Spalten aussagekräftige Namen zu.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to know the price in Euros\n",
    "\n",
    "wine_reviews[\"price in EUR\"] = wine_reviews[\"price\"] * 0.93            # USD ≈ 0.93 EUR as of September 2024\n",
    "\n",
    "wine_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews[\"quality/price ratio\"] = wine_reviews[\"points\"] / wine_reviews[\"price\"]\n",
    "\n",
    "wine_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Dropping\n",
    "\n",
    "You can drop a column or row from a DataFrame using the `drop()` method. This method allows you to remove specific rows or columns based on labels or indices.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "## Löschen\n",
    "\n",
    "Mit der Methode `drop()` können Sie eine Spalte oder Zeile aus einem DataFrame entfernen. Diese Methode ermöglicht es Ihnen, bestimmte Zeilen oder Spalten auf der Grundlage von Bezeichnungen oder Indizes zu entfernen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### Dropping a Column\n",
    "To drop a column, specify the column's name either with `columns=[]` or by using the `axis=1` argument in the `drop()` method, as columns are along the second axis (axis 1).\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "#### Löschen einer Spalte\n",
    "Um eine Spalte auszulassen, geben Sie den Namen der Spalte entweder mit `columns=[]` oder mit dem Argument `axis=1` in der Methode `drop()` an, da die Spalten auf der zweiten Achse (Achse 1) liegen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews_cleaned = wine_reviews.drop(columns=[\"quality/price ratio\"])\n",
    "\n",
    "# is equivalent to\n",
    "\n",
    "wine_reviews_cleaned =  wine_reviews.drop([\"quality/price ratio\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "You may have noticed that we assigned the operation to a new DataFrame. If you'd prefer to modify the original DataFrame directly, you can use the `inplace` parameter.\n",
    "\n",
    "However, you must be careful: `inplace=True` can sometimes raise errors due to how `pandas` manages views and copies. \n",
    "To avoid these issues, it's often safer to avoid `inplace=True` and explicitly reassign the result of the operation to your DataFrame or Series.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Sie haben vielleicht bemerkt, dass wir die Operation einem neuen DataFrame zugewiesen haben. Wenn Sie den ursprünglichen DataFrame lieber direkt ändern möchten, können Sie den Parameter `inplace` verwenden.\n",
    "\n",
    "Sie müssen jedoch vorsichtig sein: `inplace=True` kann manchmal zu Fehlern führen, da `pandas` Ansichten und Kopien verwaltet.\n",
    "Um diese Probleme zu vermeiden, ist es oft sicherer, `inplace=True` zu vermeiden und das Ergebnis der Operation explizit dem DataFrame oder der Serie neu zuzuweisen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.drop(columns=[\"price in EUR\"], inplace=True)\n",
    "\n",
    "# is equivalent to\n",
    "\n",
    "wine_reviews.drop([\"price in EUR\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "\n",
    "#### Dropping a Row\n",
    "To drop a row, you use `axis=0`, since rows are along the first axis (axis 0). You can also omit the axis, since `axis=0` is the default value:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "\n",
    "#### Löschen einer Zeile\n",
    "Um eine Zeile zu löschen, verwenden Sie `axise=0`, da die Zeilen entlang der ersten Achse (Achse 0) liegen. Sie können die Achse auch weglassen, da `axis=0` der Standardwert ist:\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.drop([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "If you attempt to drop a row or column that doesn’t exist, pandas will raise a `KeyError`. You can avoid this by setting the `errors` parameter to `'ignore'`.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "Wenn Sie versuchen, eine Zeile oder Spalte zu löschen, die nicht existiert, löst Pandas einen `KeyError` aus. Sie können dies vermeiden, indem Sie den Parameter `errors` auf `'ignore` setzen.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.drop('non_existent_column', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.drop('non_existent_column', axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = pd.read_csv('datasets/element-data.csv', na_values='-')\n",
    "\n",
    "elements.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements[(elements['melting point /K'] > 1000) & (elements['atomic radius /pm'] > 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "####  Exercise\n",
    "\n",
    "The file `element-data.csv`, available in the `datasets` folder, contains comma-separated, tabular data concerning the properties of the elements. \n",
    "To handle missing data (represented by the `-` character) when loading the `element-data.csv` file, you can pass the appropriate argument to the `read_csv()` function in `pandas`:\n",
    "`elements = pd.read_csv('datasets/element-data.csv', na_values='-')`\n",
    "\n",
    "1. Create new columns converting the radius in pm to Ångstrom and both temperatures to Celsius.\n",
    "\n",
    "2. Determine the state of each element at 298 K. Create three separate DataFrames classifying the elements into solid, liquid, or gas based on their melting and boiling points depending on the following conditions:\n",
    "- Gas: Boiling point < 298 K\n",
    "- Liquid: Melting point < 298 K ≤ Boiling point\n",
    "- Solid: Melting point > 298 K\n",
    "\n",
    "\n",
    "3. For the `abundance` column, replace missing values with `0`, as elements with no recorded abundance can be assumed to have negligible abundance. \n",
    "Use `fillna()` to replace missing values.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "####  Übung\n",
    "1. Welches ist der beste Wein, den ich für einen bestimmten Preis kaufen kann?\n",
    "Gruppieren Sie die Weine nach Preis, ermitteln Sie die Höchstpunktzahl für jede Gruppe und sortieren Sie das Ergebnis nach Preis.\n",
    "\n",
    "2. Welches sind die Mindest- und Höchstpreise für die einzelnen Weinsorten?\n",
    "Gruppieren Sie die Weine nach Sorten und berechnen Sie die Mindest- und Höchstwerte für jede Gruppe.\n",
    "\n",
    "3. Welches sind die teuersten Weinsorten? Erstellen Sie eine Variable `sorted_varieties`, die eine Kopie des DataFrame aus der vorherigen Frage enthält, in der die Sorten in absteigender Reihenfolge zuerst nach dem Mindestpreis und dann nach dem Höchstpreis sortiert sind, um Gleichstände zu vermeiden.\n",
    "\n",
    "4. Welche Kombination von Ländern und Rebsorten ist am häufigsten? Gruppieren Sie die Daten nach {Land, Sorte} Paaren. Ein in den USA erzeugter Pinot Noir würde beispielsweise als {\"US\", \"Pinot Noir\"} gruppiert werden. \n",
    "Zählen Sie nach der Gruppierung die Vorkommen der einzelnen Kombinationen und sortieren Sie die Ergebnisse in absteigender Reihenfolge nach der Anzahl der Weine.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **Filtering Based on Conditions**:\n",
    "   - **Task**: Filter the dataset to show only elements with a melting point above 1000 K and an atomic radius greater than 100 pm. Assign the result to a new DataFrame.\n",
    "     - Use boolean indexing for filtering.\n",
    "\n",
    "   ```python\n",
    "   high_melting_radius = element_data[(element_data['melting point/K'] > 1000) & (element_data['atomic radius/pm'] > 100)]\n",
    "   ```\n",
    "\n",
    "### 3. **Creating New Columns**:\n",
    "   - **Task**: Create a new column `density_category` that categorizes elements as `Low Density`, `Medium Density`, or `High Density` based on the `density/kg.m-3` values: \n",
    "     - Low Density: below 5000\n",
    "     - Medium Density: between 5000 and 10000\n",
    "     - High Density: above 10000\n",
    "\n",
    "   ```python\n",
    "   element_data['density_category'] = pd.cut(element_data['density/kg.m-3'], \n",
    "                                             bins=[-1, 5000, 10000, float('inf')], \n",
    "                                             labels=['Low Density', 'Medium Density', 'High Density'])\n",
    "   ```\n",
    "\n",
    "### 4. **Assigning Values to Filtered Data**:\n",
    "   - **Task**: For elements that have a boiling point but no melting point (`NaN` in `melting point/K` but a valid value in `boiling point/K`), assign a value of `0` to the missing melting points.\n",
    "     - Use boolean indexing and `loc` for assignment.\n",
    "\n",
    "   ```python\n",
    "   element_data.loc[element_data['melting point/K'].isna() & element_data['boiling point/K'].notna(), 'melting point/K'] = 0\n",
    "   ```\n",
    "\n",
    "### 5. **Filter and Modify Specific Rows**:\n",
    "   - **Task**: Identify elements with atomic numbers (`Z`) greater than 50 and assign a new column `classification` with the value `Heavy Element`.\n",
    "     - Use filtering and assignment.\n",
    "\n",
    "   ```python\n",
    "   element_data.loc[element_data['Z'] > 50, 'classification'] = 'Heavy Element'\n",
    "   ```\n",
    "\n",
    "### 6. **Creating Calculated Columns**:\n",
    "   - **Task**: Create a new column called `boiling_melting_diff` that calculates the difference between the boiling point and the melting point for each element. Handle missing values by setting the difference to `NaN` if either boiling or melting point is missing.\n",
    "     - Use subtraction with `fillna()` or `dropna()` to handle missing values.\n",
    "\n",
    "   ```python\n",
    "   element_data['boiling_melting_diff'] = element_data['boiling point/K'] - element_data['melting point/K']\n",
    "   ```\n",
    "\n",
    "### 7. **Advanced Filtering and Assigning Values**:\n",
    "   - **Task**: For elements with a density greater than 7000 kg/m³ but a missing value in `atomic radius/pm`, assign an approximate atomic radius value of `150 pm`.\n",
    "     - Use boolean indexing combined with `loc`.\n",
    "\n",
    "   ```python\n",
    "   element_data.loc[element_data['density/kg.m-3'] > 7000 & element_data['atomic radius/pm'].isna(), 'atomic radius/pm'] = 150\n",
    "   ```\n",
    "\n",
    "### 8. **Replacing Missing Values in Specific Columns**:\n",
    "   - **Task**: For the `abundance` column, replace missing values with `0`, as elements with no recorded abundance can be assumed to have negligible abundance.\n",
    "     - Use `fillna()` to replace missing values.\n",
    "\n",
    "   ```python\n",
    "   element_data['aboundance'].fillna(0, inplace=True)\n",
    "   ```\n",
    "\n",
    "### 9. **Setting Values Based on Indexing**:\n",
    "   - **Task**: Set the atomic weight of hydrogen (H) to exactly `1.008 Da`. Use the element's symbol (`H`) to locate the row and assign the new value.\n",
    "     - Use `.loc` with the symbol for indexing and assignment.\n",
    "\n",
    "   ```python\n",
    "   element_data.loc[element_data['symbol'] == 'H', 'atomic weight/Da'] = 1.008\n",
    "   ```\n",
    "\n",
    "### 10. **Filtering and Assigning for Multiple Conditions**:\n",
    "   - **Task**: For elements with atomic numbers greater than 20 and density above 5000 kg/m³, assign a new column `metal_status` with the value `Metal`. If the density is below 5000 kg/m³, assign `Non-metal`.\n",
    "     - Use boolean indexing with `np.where()` or conditional assignment.\n",
    "\n",
    "   ```python\n",
    "   element_data['metal_status'] = np.where((element_data['Z'] > 20) & (element_data['density/kg.m-3'] > 5000), 'Metal', 'Non-metal')\n",
    "   ```\n",
    "\n",
    "### 11. **Handling Negative Values (as a filtering and assigning task)**:\n",
    "   - **Task**: Check if there are any negative values in the dataset (e.g., in the `density` or `melting point` columns). If any are found, replace them with `NaN` as negative values are not physically meaningful.\n",
    "     - Use filtering and `replace()`.\n",
    "\n",
    "   ```python\n",
    "   element_data.loc[element_data['density/kg.m-3'] < 0, 'density/kg.m-3'] = pd.NA\n",
    "   ```\n",
    "\n",
    "These tasks help practice common pandas operations like indexing, filtering, handling missing data, creating new columns, and assigning values—all key skills when working with real-world datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "   \n",
    "# Load the Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "titanic = titanic[['survived', 'pclass', 'sex', 'age', 'fare', 'embark_town']]\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic['age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "####  Exercise\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "1. Load the Titanic dataset into pandas:\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   import pandas as pd\n",
    "   \n",
    "   # Load the Titanic dataset\n",
    "   titanic = sns.load_dataset('titanic')\n",
    "   ```\n",
    "2. Inspect the dataset and its basic information with the commands we have seen at the beginning of the lesson.\n",
    "\n",
    "3. Some columns are redundant: create another dataset by selecting only the following columns: `survived`, `pclass`, `sex`, `age`, `fare`, and `embark_town`.\n",
    "\n",
    "4. Drop rows where the `survived` column is missing.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "####  Übung\n",
    "Am 15. April 1912 sank die als \"unsinkbar\" geltende RMS Titanic während ihrer Jungfernfahrt nach der Kollision mit einem Eisberg. Leider gab es nicht genügend Rettungsboote für alle Passagiere an Bord, was zum Tod von 1502 der 2224 Passagiere und Besatzungsmitglieder führte.\n",
    "\n",
    "Auch wenn das Überleben ein gewisses Glücksspiel war, so scheint es doch, dass einige Gruppen von Menschen eher überlebten als andere.\n",
    "\n",
    "1. Laden Sie den Titanic-Datensatz in Pandas:\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   import pandas as pd\n",
    "   \n",
    "   # Laden des Titanic-Datensatzes\n",
    "   titanic = sns.load_dataset('titanic')\n",
    "   ```\n",
    "2. Überprüfen Sie den Datensatz und seine grundlegenden Informationen mit den Befehlen, die wir zu Beginn der Lektion gesehen haben.\n",
    "\n",
    "3. Einige Spalten sind überflüssig: Erstellen Sie einen weiteren Datensatz, indem Sie nur die folgenden Spalten auswählen: `survived`, `pclass`, `sex`, `age`, `fare`, and `embark_town`.\n",
    "\n",
    "4. Streichen Sie Zeilen, in denen die Spalte `survived` fehlt.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nequip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
