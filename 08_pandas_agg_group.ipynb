{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output, HTML\n",
    "import time\n",
    "\n",
    "def countdown_timer(minutes):\n",
    "    total_seconds = minutes * 60\n",
    "    for seconds in range(total_seconds, 0, -1):\n",
    "        mins, secs = divmod(seconds, 60)\n",
    "        time_str = f\"{mins:02}'{secs:02}''\"\n",
    "        clear_output(wait=True)\n",
    "        # HTML with styling\n",
    "        display(HTML(f'<div style=\"font-size: 24px; color: blue; font-weight: bold;\">Time remaining: {time_str}</div>'))\n",
    "        time.sleep(1)\n",
    "    clear_output(wait=True)\n",
    "    # Final message with different styling\n",
    "    display(HTML('<div style=\"font-size: 24px; color: green; font-weight: bold;\">Time\\'s up!</div>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg\" style=\"width: 500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine_reviews = pd.read_csv('datasets/wine_reviews_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/06_aggregate.svg\" style=\"height: 150px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Summary statistics\n",
    "\n",
    "The `describe()` method provides basic statistics for the numerical data in the dataset. By default, it excludes textual data from the analysis.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "## Zuweisung von Werten\n",
    "\n",
    "Die Methode `describe()` liefert grundlegende Statistiken für die numerischen Daten im Datensatz. Standardmäßig schließt sie Textdaten von der Analyse aus.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "While the `describe()` function in Pandas provides a broad summary of basic statistics for numerical data, it only scratches the surface of what is needed for comprehensive data analysis. Specific functions are essential for more targeted insights. \n",
    "\n",
    "**Focused Insights:**\n",
    "- `mean()`, `sum()`, `min()`, `max()`: When analyzing large datasets, there are cases where we are only interested in a specific metric (e.g., the mean or total sum) rather than a full statistical overview. Using specific functions allows for more direct access and avoids cluttering the output with unnecessary statistics.\n",
    "    - Example: If you need to compute the total revenue from a dataset, using `df['revenue'].sum()` is much faster and more efficient than relying on `describe()`.\n",
    "- To locate rows with extreme values (such as finding the most expensive or cheapest wine in a dataset), use `idxmin()` and `idxmax()`.\n",
    "Unlike `min()` and `max()`, which return the actual value, `idxmin()` and `idxmax()` help you identify where in your data those values are located.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.25;color: grey;\">\n",
    "\n",
    "Während die Funktion `describe()` in Pandas eine breite Zusammenfassung grundlegender Statistiken für numerische Daten bietet, kratzt sie nur an der Oberfläche dessen, was für eine umfassende Datenanalyse erforderlich ist. Für gezieltere Einblicke sind spezifische Funktionen unerlässlich.\n",
    "\n",
    "**Fokussierte Einblicke:**\n",
    "- `mean()`, `sum()`, `min()`, `max()`: Bei der Analyse großer Datensätze gibt es Fälle, in denen wir nur an einer bestimmten Metrik (z. B. dem Mittelwert oder der Gesamtsumme) und nicht an einem vollständigen statistischen Überblick interessiert sind. Die Verwendung spezifischer Funktionen ermöglicht einen direkteren Zugriff und vermeidet eine Überfrachtung der Ausgabe mit unnötigen Statistiken.\n",
    "   - Beispiel: Wenn Sie die Gesamteinnahmen aus einem Datensatz berechnen müssen, ist die Verwendung von `df['revenue'].sum()` viel schneller und effizienter als die Verwendung von `describe()`.\n",
    "- Um Zeilen mit extremen Werten zu finden (z. B. um den teuersten oder billigsten Wein in einem Datensatz zu finden), verwenden Sie `idxmin()` und `idxmax()`.\n",
    "Im Gegensatz zu `min()` und `max()`, die den tatsächlichen Wert zurückgeben, helfen `idxmin()` und `idxmax()` dabei, herauszufinden, wo in Ihren Daten diese Werte zu finden sind.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "2. Advanced Statistical Metrics:\n",
    "   - `quantile()`, `mode()`, `skew()`, `kurt()`: These functions provide deeper statistical insights, such as percentiles, data distribution shapes (skewness and kurtosis), and the mode, which are not provided by `describe()`. For example, understanding skewness is essential when analyzing data distributions to identify potential biases.\n",
    "   - Example: In financial data, the skewness of returns helps assess the risk of extreme outcomes, which is critical for decision-making.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "2. Erweiterte statistische Metriken:\n",
    "   - `quantile()`, `mode()`, `skew()`, `kurt()`: Diese Funktionen bieten tiefere statistische Einblicke, wie z. B. Perzentile, Datenverteilungsformen (Schiefe und Kurtosis) und den Modus, die von `describe()` nicht bereitgestellt werden. Das Verständnis der Schiefe ist z. B. bei der Analyse von Datenverteilungen wichtig, um mögliche Verzerrungen zu erkennen.\n",
    "   - Beispiel: Bei Finanzdaten hilft die Schiefe der Renditen bei der Bewertung des Risikos extremer Ergebnisse, was für die Entscheidungsfindung entscheidend ist.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "3. Working with Categorical Data:\n",
    "   - `value_counts()`: While `describe()` excludes non-numeric data by default, `value_counts()` is an essential tool for summarizing categorical data, allowing you to see the frequency of different categories in a column.\n",
    "   - Example: In a dataset of customer feedback, you may want to see the frequency of responses like \"positive\", \"negative\", or \"neutral\" using `df['feedback'].value_counts()`.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "3. Arbeiten mit kategorialen Daten:\n",
    "   - `value_counts()`: Während `describe()` nicht-numerische Daten standardmäßig ausschließt, ist `value_counts()` ein wichtiges Werkzeug für die Zusammenfassung kategorischer Daten, mit dem Sie die Häufigkeit der verschiedenen Kategorien in einer Spalte sehen können.\n",
    "   - Beispiel: In einem Datensatz mit Kundenfeedback möchten Sie vielleicht die Häufigkeit von Antworten wie \"positiv\", \"negativ\" oder \"neutral\" mit `df['feedback'].value_counts()` sehen.\n",
    "   \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "4. Cumulative and Pairwise Operations:\n",
    "   - `cumsum()`, `cumprod()`, `corr()`, `cov()`: These functions allow for cumulative sums/products and pairwise correlations/covariances, which are crucial for time series data analysis and financial modeling. `describe()` does not provide any cumulative or pairwise measures.\n",
    "   - Example: In stock price analysis, cumulative returns are often more meaningful than simple returns, making `cumsum()` and `cumprod()` critical.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "4. Kumulative und paarweise Operationen:\n",
    "   - `cumsum()`, `cumprod()`, `corr()`, `cov()`: Diese Funktionen ermöglichen kumulative Summen/Produkte und paarweise Korrelationen/Kovarianzen, die für die Analyse von Zeitreihendaten und die Finanzmodellierung entscheidend sind. Die Funktion `describe()` liefert keine kumulativen oder paarweisen Maße.\n",
    "   - Beispiel: Bei der Analyse von Aktienkursen sind kumulierte Renditen oft aussagekräftiger als einfache Renditen, weshalb `cumsum()` und `cumprod()` von entscheidender Bedeutung sind.\n",
    "   \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "5. Handling Missing Data:\n",
    "   - `count()`: While `describe()` provides the count of non-null values, using `count()` directly gives more flexibility to count non-null values for specific columns or the entire DataFrame, making it easier to identify missing data patterns.\n",
    "   - Example: When handling missing data in a large dataset, `df['column'].count()` gives a clear view of how many entries are available in a specific column.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "5. Behandlung fehlender Daten:\n",
    "   - `count()`: Während `describe()` die Anzahl der Nicht-Null-Werte liefert, bietet die direkte Verwendung von `count()` mehr Flexibilität, um Nicht-Null-Werte für bestimmte Spalten oder den gesamten DataFrame zu zählen, was es einfacher macht, Muster für fehlende Daten zu erkennen.\n",
    "   - Beispiel: Beim Umgang mit fehlenden Daten in einem großen Datensatz gibt `df['column'].count()` einen klaren Überblick darüber, wie viele Einträge in einer bestimmten Spalte vorhanden sind.\n",
    "   \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Syntax            | Description                                          | Beschreibung                                   |\n",
    "|-------------------|------------------------------------------------------|------------------------------------------------|\n",
    "|                   |       **Summarization & Basic Statistics**           |     **Zusammenfassung und grundlegende Statistik**       |\n",
    "| `describe()`      | Provides summary statistics for numerical data       | Liefert statistische Kennzahlen für numerische Daten |\n",
    "| `count()`         | Counts the non-NA/null entries                       | Zählt die nicht-NA/null Einträge               |\n",
    "| `size()`          | Returns the number of total elements (including NaN) | Gibt die Gesamtanzahl der Elemente zurück (einschließlich NaN) |\n",
    "| `nunique()`       | Counts the number of unique values                   | Zählt die Anzahl einzigartiger Werte           |\n",
    "| `quantile(0.25)`  | Returns the 25th percentile                          | Gibt das 25. Perzentil zurück                  |\n",
    "| `mean()`          | Calculates the mean of numerical data                | Berechnet den Durchschnitt numerischer Daten   |\n",
    "| `median()`        | Returns the median of values                         | Gibt den Median der Werte zurück               |\n",
    "| `min()`           | Returns the minimum value                            | Gibt den Minimalwert zurück                    |\n",
    "| `max()`           | Returns the maximum value                            | Gibt den Maximalwert zurück                    |\n",
    "| `sum()`           | Computes the sum of values                           | Berechnet die Summe der Werte                  |\n",
    "| `std()`           | Computes the standard deviation                      | Berechnet die Standardabweichung               |\n",
    "| `var()`           | Computes the variance                                | Berechnet die Varianz                          |\n",
    "|                   |   **Cumulative Operations**            |                **Kumulative Operationen**                                |\n",
    "| `cumsum()`        | Computes the cumulative sum of values                | Berechnet die kumulative Summe der Werte       |\n",
    "| `cumprod()`       | Computes the cumulative product of values            | Berechnet das kumulative Produkt der Werte     |\n",
    "| `cummin()`        | Computes the cumulative minimum                      | Berechnet das kumulative Minimum               |\n",
    "| `cummax()`        | Computes the cumulative maximum                      | Berechnet das kumulative Maximum               |\n",
    "|                   |    **Distribution & Frequency**               |        **Verbreitung und Häufigkeit**                                        |\n",
    "| `mode()`          | Returns the mode (most frequent value)               | Gibt den Modus (häufigster Wert) zurück        |\n",
    "| `value_counts()`  | Returns the frequency of unique values               | Gibt die Häufigkeit einzigartiger Werte zurück |\n",
    "|                   |     **Correlation & Covariance**          |         **Korrelation und Kovarianz**                                       |\n",
    "| `corr()`          | Computes pairwise correlation of columns             | Berechnet die paarweise Korrelation der Spalten|\n",
    "| `cov()`           | Computes pairwise covariance                         | Berechnet die paarweise Kovarianz              |\n",
    "|                   |  **Distribution Shape**            |      **Verteilungsform**         |\n",
    "| `skew()`          | Returns the skewness of the distribution             | Gibt die Schiefe der Verteilung zurück         |\n",
    "| `kurt()`          | Returns the kurtosis of the distribution             | Gibt die Kurtosis der Verteilung zurück        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews[['price','points']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "1. What is the median of the points in the `wine_reviews` dataset?\n",
    "\n",
    "2. What countries are represented in the dataset? (Your answer should not include any duplicates.)\n",
    "\n",
    "3. How often does each country appear in the dataset?\n",
    "\n",
    "4. Which wine has the highest points-to-price ratio?\n",
    "\n",
    "5. A rating system ranging from 80 to 100 points is too hard to understand: we'd like to translate them into simple star ratings. A score of 95 or higher counts as 3 stars, a score of at least 85 but less than 95 is 2 stars. Any other score is 1 star. Create a column with the number of stars corresponding to each review in the dataset.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "1. Was ist der Median der Punkte im Datensatz `wine_reviews`?\n",
    "\n",
    "2. Welche Länder sind in dem Datensatz vertreten? (Ihre Antwort sollte keine Duplikate enthalten.)\n",
    "\n",
    "3. Wie oft taucht jedes Land in dem Datensatz auf?\n",
    "\n",
    "4. Welcher Wein hat das höchste Preis-Punkte-Verhältnis?\n",
    "\n",
    "5. Ein Bewertungssystem, das von 80 bis 100 Punkten reicht, ist zu schwer zu verstehen: Wir würden sie gerne in einfache Sternebewertungen umwandeln. Eine Punktzahl von 95 oder höher zählt als 3 Sterne, eine Punktzahl von mindestens 85, aber weniger als 95 ist 2 Sterne. Jede andere Bewertung ist 1 Stern. Erstellen Sie eine Spalte mit der Anzahl der Sterne für jede Bewertung im Datensatz.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign 3 stars where 'points' >= 95\n",
    "wine_reviews.loc[wine_reviews['points'] >= 95, 'star_rating'] = 3\n",
    "\n",
    "# Assign 2 stars where 'points' is between 85 and 95\n",
    "wine_reviews.loc[(wine_reviews['points'] >= 85) & (wine_reviews['points'] < 95), 'star_rating'] = 2\n",
    "\n",
    "# Assign 1 star for any other scores\n",
    "wine_reviews.loc[wine_reviews['points'] < 85, 'star_rating'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews['star_rating_alt'] = pd.cut(wine_reviews['points'], bins=[80, 85, 95, 100], labels=['1', '2', '3'])\n",
    "\n",
    "wine_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Sorting\n",
    "\n",
    "The `sort_values()` function in `pandas` allows you to sort a DataFrame by one or more columns, either in ascending or descending order. It’s a versatile tool for organizing data based on specified criteria.\n",
    "\n",
    "- `by`: The column(s) to sort by. You can pass a single column name as a string or multiple column names as a list.\n",
    "- `ascending`: A boolean or a list of booleans that determines the sort order. `True` sorts in ascending order (default), and `False` sorts in descending order.\n",
    "- `inplace`: If `True`, the sorting operation will modify the DataFrame in place without returning a new DataFrame.\n",
    "- `na_position`: Specifies the position of `NaN` values, either `'first'` or `'last'`.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "## Sortieren\n",
    "\n",
    "Die Funktion `sort_values()` in `pandas` ermöglicht es Ihnen, einen DataFrame nach einer oder mehreren Spalten zu sortieren, entweder in aufsteigender oder absteigender Reihenfolge. Sie ist ein vielseitiges Werkzeug, um Daten nach bestimmten Kriterien zu ordnen.\n",
    "\n",
    "- `by`: Die Spalte(n), nach denen sortiert werden soll. Sie können einen einzelnen Spaltennamen als String oder mehrere Spaltennamen als Liste übergeben.\n",
    "- `ascending`: Ein boolescher Wert oder eine Liste von booleschen Werten, die die Sortierreihenfolge bestimmen. True\" sortiert in aufsteigender Reihenfolge (Voreinstellung), und \"False\" sortiert in absteigender Reihenfolge.\n",
    "- `inplace`: Wenn `True`, wird die Sortieroperation den DataFrame an Ort und Stelle ändern, ohne einen neuen DataFrame zurückzugeben.\n",
    "- `na_position`: Gibt die Position der `NaN`-Werte an, entweder `'first'` oder `'last'`.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df.sort_values(by='column_name', ascending=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by a Single Column\n",
    "\n",
    "# Sorting the DataFrame by the 'points' column in ascending order\n",
    "wine_reviews_sorted = wine_reviews.sort_values(by='points', ascending=True)\n",
    "\n",
    "wine_reviews_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by Multiple Columns\n",
    "\n",
    "# Sorting by 'points' in descending order, then by 'price' in ascending order\n",
    "wine_reviews_sorted = wine_reviews.sort_values(by=['points', 'price'], ascending=[False, True])\n",
    "\n",
    "wine_reviews_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame in place\n",
    "\n",
    "wine_reviews.sort_values(by='points', ascending=False, inplace=True)\n",
    "\n",
    "wine_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Missing Values\n",
    "\n",
    "# Sorting by 'points' and placing NaN values at the beginning\n",
    "wine_reviews_sorted = wine_reviews.sort_values(by='designation', ascending=True, na_position='first')\n",
    "\n",
    "wine_reviews_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/06_groupby.svg\" style=\"height: 300px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Grouping\n",
    "\n",
    "Let’s say we want to group the dataset by the `country` column and calculate the average `points` for each country.\n",
    "\n",
    "We can group the data by `country` and compute the mean of the `points` for each group (i.e., each country).\n",
    "\n",
    "The `groupby()` function in `pandas` is used precisely to group data based on the values in one or more columns. \n",
    "\n",
    "It’s particularly useful for aggregating, summarizing, or transforming data by applying a function (like `sum()`, `mean()`, etc.) to each group.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "## Gruppierung\n",
    "\n",
    "Nehmen wir an, wir wollen den Datensatz nach der Spalte \"Land\" gruppieren und die durchschnittlichen \"Punkte\" für jedes Land berechnen.\n",
    "\n",
    "Wir können die Daten nach \"Land\" gruppieren und den Mittelwert der \"Punkte\" für jede Gruppe (d. h. jedes Land) berechnen.\n",
    "\n",
    "Die Funktion `groupby()` in `pandas` wird genau dazu verwendet, Daten auf der Grundlage der Werte in einer oder mehreren Spalten zu gruppieren.\n",
    "\n",
    "Sie ist besonders nützlich, um Daten zu aggregieren, zusammenzufassen oder umzuwandeln, indem eine Funktion (wie `sum()`, `mean()`, usw.) auf jede Gruppe angewendet wird.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df.groupby('column_name').agg_function()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv('datasets/wine_reviews_sample.csv')      # Let's reload the dataset for a fresh start\n",
    "\n",
    "wine_reviews.groupby('country')['points'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also apply multiple aggregation functions at once:\n",
    "\n",
    "wine_reviews.groupby('country')['points'].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Determine the data type returned by each of the two previous `groupby` commands.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### Übung\n",
    "\n",
    "Bestimmen Sie den Datentyp, der von jedem der beiden vorangegangenen `groupby`-Befehle zurückgegeben wird.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "The output of `groupby()` is, by default, sorted by the group labels. But what if we want to sort it by the result of the aggregation function we just applied?\n",
    "\n",
    "We can apply `sort_values()`, and `pandas` offers a very efficient way to handle this directly:\n",
    "\n",
    "**Chaining** in `pandas` refers to the practice of *applying multiple methods consecutively in a single line of code*. \n",
    "\n",
    "This allows you to perform a series of operations step by step, without needing to store intermediate results in separate variables. \n",
    "\n",
    "It's a clean and efficient way to work with data.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Die Ausgabe von `groupby()` wird standardmäßig nach den Gruppenbezeichnungen sortiert. Was aber, wenn wir sie nach dem Ergebnis der gerade angewandten Aggregationsfunktion sortieren wollen?\n",
    "\n",
    "Wir können `sort_values()` anwenden, und `pandas` bietet eine sehr effiziente Möglichkeit, dies direkt zu tun:\n",
    "\n",
    "*Chaining* in `pandas` bezieht sich auf die Praxis der *Anwendung mehrerer Methoden nacheinander in einer einzigen Codezeile*.\n",
    "\n",
    "Dadurch können Sie eine Reihe von Operationen Schritt für Schritt durchführen, ohne Zwischenergebnisse in separaten Variablen speichern zu müssen.\n",
    "\n",
    "Dies ist eine saubere und effiziente Art, mit Daten zu arbeiten.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.groupby('country')['points'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "# Exercises\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "# Übungen\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-light\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.3;<div style=\"width: 48%; line-height: 1.3;\">\n",
    "\n",
    "####  Exercise\n",
    "1. What is the best wine I can buy for a given price?\n",
    "Group the wines by price, find the maximum points for each group, and sort the result by price.\n",
    "\n",
    "2. What are the minimum and maximum prices for each wine variety?\n",
    "Group the wines by variety and calculate the minimum and maximum values for each group.\n",
    "\n",
    "3. What are the most expensive wine varieties? Create a variable `sorted_varieties` that contains a copy of the DataFrame from the previous question, where varieties are sorted in descending order first by minimum price, and then by maximum price to break ties.\n",
    "\n",
    "4. What combination of countries and wine varieties are most common? Group the data by {country, variety} pairs. For example, a Pinot Noir produced in the US would be grouped as {\"US\", \"Pinot Noir\"}. \n",
    "After grouping, count the occurrences of each combination and sort the results in descending order based on the wine count.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "####  Übung\n",
    "1. Welches ist der beste Wein, den ich für einen bestimmten Preis kaufen kann?\n",
    "Gruppieren Sie die Weine nach Preis, ermitteln Sie die Höchstpunktzahl für jede Gruppe und sortieren Sie das Ergebnis nach Preis.\n",
    "\n",
    "2. Welches sind die Mindest- und Höchstpreise für die einzelnen Weinsorten?\n",
    "Gruppieren Sie die Weine nach Sorten und berechnen Sie die Mindest- und Höchstwerte für jede Gruppe.\n",
    "\n",
    "3. Welches sind die teuersten Weinsorten? Erstellen Sie eine Variable `sorted_varieties`, die eine Kopie des DataFrame aus der vorherigen Frage enthält, in der die Sorten in absteigender Reihenfolge zuerst nach dem Mindestpreis und dann nach dem Höchstpreis sortiert sind, um Gleichstände zu vermeiden.\n",
    "\n",
    "4. Welche Kombination von Ländern und Rebsorten ist am häufigsten? Gruppieren Sie die Daten nach {Land, Sorte} Paaren. Ein in den USA erzeugter Pinot Noir würde beispielsweise als {\"US\", \"Pinot Noir\"} gruppiert werden. \n",
    "Zählen Sie nach der Gruppierung die Vorkommen der einzelnen Kombinationen und sortieren Sie die Ergebnisse in absteigender Reihenfolge nach der Anzahl der Weine.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdown_timer(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.groupby('price')['points'].max().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews.groupby(['country', 'variety']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://pandas.pydata.org/docs/_images/08_concat_row.svg\" style=\"height: 250px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "## Combining multiple datasets\n",
    "\n",
    "Combining datasets in `pandas` allows you to bring together data from multiple DataFrames.\n",
    "\n",
    "#### `pd.concat()`\n",
    "\n",
    "The `pd.concat()` function performs concatenation operations of multiple tables along one of the axes (row-wise or column-wise).\n",
    "\n",
    "Suppose we have two datasets with similar structures, and we want to combine them into a single table by stacking one below the other.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.5;color: grey;\">\n",
    "\n",
    "## Kombination mehrerer Datensätze\n",
    "\n",
    "Die Kombination von Datensätzen in \"Pandas\" ermöglicht es Ihnen, Daten aus mehreren DataFrames zusammenzuführen.\n",
    "\n",
    "#### `pd.concat()`\n",
    "\n",
    "Die Funktion `pd.concat()` führt Verkettungsoperationen von mehreren Tabellen entlang einer der Achsen (zeilenweise oder spaltenweise) durch.\n",
    "\n",
    "Angenommen, wir haben zwei Datensätze mit ähnlicher Struktur und möchten sie in einer einzigen Tabelle kombinieren, indem wir sie übereinander stapeln.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "result = pd.concat([df1, df2], axis=0)  # Vertical concatenation (default)\n",
    "result = pd.concat([df1, df2], axis=1)  # Horizontal concatenation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_no2 = pd.read_csv(\"datasets/air_quality_no2_long.csv\", parse_dates=True)\n",
    "\n",
    "air_quality_no2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_pm25 = pd.read_csv(\"datasets/air_quality_pm25_long.csv\", parse_dates=True)\n",
    "\n",
    "air_quality_pm25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.concat([air_quality_pm25, air_quality_no2], axis=0)\n",
    "\n",
    "air_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "Here, we have appended `air_quality_no2` below `air_quality_pm25`.\n",
    "\n",
    "However, we notice that air_quality_pm25 and air_quality_no2 not only share the same structure but also have identical values in several columns (`city`, `country`, `date.utc`, `location`, and `unit`), except for `parameter` and `value`. \n",
    "\n",
    "It would be more efficient to combine them into a single DataFrame where `no2` and `pm25` are represented as two separate columns.\n",
    "\n",
    "To achieve this, we first clean up the two DataFrames by removing the `parameter` column and renaming the `value` column to `no2` and `pm25`, respectively:\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "Hier haben wir `air_quality_no2` unter `air_quality_pm25` angehängt.\n",
    "\n",
    "Es fällt jedoch auf, dass air_quality_pm25 und air_quality_no2 nicht nur dieselbe Struktur haben, sondern auch in mehreren Spalten (`city`, `country`, `date.utc`, `location` und `unit`) identische Werte aufweisen, mit Ausnahme von `parameter` und `value`.\n",
    "\n",
    "Es wäre effizienter, sie in einem einzigen DataFrame zusammenzufassen, in dem `no2` und `pm25` als zwei separate Spalten dargestellt werden.\n",
    "\n",
    "Um dies zu erreichen, bereinigen wir zunächst die beiden DataFrames, indem wir die Spalte `parameter` entfernen und die Spalte `value` in `no2` bzw. `pm25` umbenennen:\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'parameter' column since it's no longer needed\n",
    "pm25 = air_quality_pm25.drop(columns=['parameter'])\n",
    "no2 = air_quality_no2.drop(columns=['parameter'])\n",
    "\n",
    "# Rename the 'value' columns to differentiate them\n",
    "pm25 = pm25.rename(columns={'value': 'value pm25'})\n",
    "no2 = no2.rename(columns={'value': 'value no2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "#### `pd.merge()`\n",
    "\n",
    "`pd.merge()` is a `pandas` function used to combine two DataFrames based on common columns or indexes.\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.3;color: grey;\">\n",
    "\n",
    "#### `pd.merge()`\n",
    "\n",
    "`pd.merge()` ist eine \"Pandas\"-Funktion, mit der zwei DataFrames auf der Grundlage gemeinsamer Spalten oder Indizes kombiniert werden können.\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.merge(df1, df2, on='key')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.merge(pm25, no2, \n",
    "                       on=['city', 'country', 'date.utc', 'location', 'unit'])\n",
    "\n",
    "air_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "<div style=\"width: 48%; line-height: 1.5;\">\n",
    "\n",
    "There are multiple ways to merge two DataFrames.\n",
    "\n",
    "**Inner Merge** (`how='inner'`):\n",
    "*Keeps only rows with matching keys* in both DataFrames.\n",
    "Acts like an *intersection*.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='inner', on='key')\n",
    "```\n",
    "\n",
    "**Outer Merge** (`how='outer'`):\n",
    "*Keeps all rows* from both DataFrames, filling with `NaN` for missing values.<br>\n",
    "Acts like a *union*.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='outer', on='key')\n",
    "```\n",
    "\n",
    "**Left Merge** (`how='left'`):\n",
    "*Keeps all rows from the left DataFrame (df1)* and only the matching rows from the right DataFrame (df2). \n",
    "Rows in the left DataFrame with no match in the right DataFrame will have `NaN` for the columns from the right DataFrame.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='left', on='key')\n",
    "```\n",
    "\n",
    "**Right Merge** (`how='right'`):\n",
    "*Keeps all rows from the right DataFrame (df2)* and only the matching rows from the left DataFrame (df1). \n",
    "Rows in the right DataFrame with no match in the left DataFrame will have `NaN` for the columns from the left DataFrame.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='right', on='key')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 48%; line-height: 1.4;color: grey;\">\n",
    "\n",
    "Es gibt mehrere Möglichkeiten, zwei DataFrames zusammenzuführen.\n",
    "\n",
    "`how='inner'`:\n",
    "*Behält nur Zeilen mit übereinstimmenden Schlüsseln* in beiden DataFrames.\n",
    "Wirkt wie eine *Schnittstelle*.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='inner', on='key')\n",
    "```\n",
    "\n",
    "**`how='outer'`:\n",
    "*Behält alle Zeilen* aus beiden DataFrames und füllt mit `NaN` für fehlende Werte.\n",
    "Wirkt wie eine *Zusammenführung*.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='outer', on='key')\n",
    "```\n",
    "\n",
    "**`how='left'`:\n",
    "*Behält alle Zeilen aus dem linken DataFrame (df1)* und nur die passenden Zeilen aus dem rechten DataFrame (df2).\n",
    "Zeilen im linken DataFrame, die im rechten DataFrame nicht übereinstimmen, haben `NaN` für die Spalten aus dem rechten DataFrame.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='left', on='key')\n",
    "```\n",
    "\n",
    "**`how='right'`:\n",
    "*Behält alle Zeilen aus dem rechten DataFrame (df2)* und nur die passenden Zeilen aus dem linken DataFrame (df1).\n",
    "Zeilen im rechten DataFrame, die im linken DataFrame nicht übereinstimmen, haben `NaN` für die Spalten aus dem linken DataFrame.\n",
    "  \n",
    "```python\n",
    "pd.merge(df1, df2, how='right', on='key')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1200/1*9eH1_7VbTZPZd9jBiGIyNA.png\" style=\"height: 300px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality = pd.merge(pm25, no2, \n",
    "                       on=['city', 'country', 'date.utc', 'location', 'unit'], \n",
    "                       how='outer')\n",
    "\n",
    "air_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('datasets/diabetes.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/element-data.csv', na_values='-')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop both \"Symbol\" and \"name\" columns in one step\n",
    "df.drop([\"Symbol\", \"name\"], axis=1, inplace=True)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='kendall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Basic Aggregation:**\n",
    "   - **Task**: Which element has the highest and lowest atomic radius? \n",
    "     - Use `idxmax()` and `idxmin()` to find the elements with the largest and smallest atomic radius.\n",
    "\n",
    "   - **Task**: Calculate the average atomic weight for all elements. Are there any outliers (elements significantly above or below the mean)?\n",
    "     - Use `mean()` and `std()` to find elements that are outliers.\n",
    "\n",
    "### 2. **Filtering and Querying:**\n",
    "   - **Task**: Find the elements that are more abundant than 1% in the Earth's crust but have a melting point lower than 500 K.\n",
    "     - Use filtering conditions (`query()` or boolean indexing) to find elements that meet these criteria.\n",
    "\n",
    "   - **Task**: Identify all elements with a density greater than 10,000 kg/m³ and a boiling point below 4000 K. \n",
    "     - Use filtering to identify these elements.\n",
    "\n",
    "### 3. **Grouping and Aggregation:**\n",
    "   - **Task**: Group the elements by their first letter (symbol) and calculate the average atomic weight for each group.\n",
    "     - Use `groupby()` with string manipulation to group the elements based on the first letter of their symbol.\n",
    "\n",
    "   - **Task**: What is the most common atomic weight range among elements (e.g., 0-50 Da, 50-100 Da, etc.)? \n",
    "     - Use `pd.cut()` to group elements into bins by their atomic weight and count the number of elements in each bin.\n",
    "\n",
    "### 4. **Correlations:**\n",
    "   - **Task**: Is there a correlation between atomic radius and density? \n",
    "     - Use the `corr()` function to calculate the correlation between `atomic radius/pm` and `density/kg.m-3`.\n",
    "\n",
    "   - **Task**: Explore the relationship between melting point and boiling point across elements. Which elements have an unusually high ratio between their boiling and melting points?\n",
    "     - Calculate the ratio and use sorting to identify outliers.\n",
    "\n",
    "### 5. **Data Transformation and Creation:**\n",
    "   - **Task**: Create a new column that classifies elements as \"light\" or \"heavy\" based on their atomic weight (e.g., atomic weight below 100 Da is \"light,\" above 100 Da is \"heavy\").\n",
    "     - Use `apply()` or `np.where()` to create the classification column.\n",
    "\n",
    "   - **Task**: Create a new DataFrame that contains only elements with a density higher than iron (7874 kg/m³). Sort this DataFrame by density in descending order.\n",
    "     - Use filtering and `sort_values()` to generate and sort the new DataFrame.\n",
    "\n",
    "### 6. **Advanced Grouping and Aggregation:**\n",
    "   - **Task**: Group the elements by their abundance range (e.g., very low, low, moderate, high) and calculate the average atomic weight, atomic radius, and density for each group.\n",
    "     - Use `pd.cut()` to group the elements based on abundance, followed by `groupby()` and aggregation.\n",
    "\n",
    "   - **Task**: Find the element groups (by abundance range) with the most extreme melting points (lowest and highest). \n",
    "     - Use a combination of `groupby()` and `agg()` to find these values.\n",
    "\n",
    "### 7. **Visualization (bonus task for practice):**\n",
    "   - **Task**: Plot a scatter plot showing the relationship between atomic weight and density. Color the points based on the element's abundance.\n",
    "     - Use `matplotlib` or `seaborn` to visualize the relationship.\n",
    "\n",
    "These tasks will challenge you to use a variety of pandas methods such as `groupby()`, `filter()`, `query()`, `apply()`, and `sort_values()` to explore relationships and perform data manipulation in the periodic table dataset. Let me know if you need further clarification on any of the tasks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
